// Code generated by xll-gen {{.Version}}. DO NOT EDIT.
package {{.Package}}

import (
	"context"
	"flag"
	"fmt"
	"math/rand"
	"sync"
	"time"
	"runtime"
	"runtime/debug"
	"{{.ModName}}/generated/ipc"
	"github.com/xll-gen/xll-gen/pkg/log"
	"github.com/xll-gen/xll-gen/pkg/server"
	"github.com/xll-gen/types/go/protocol"
	"github.com/xll-gen/shm/go"
	flatbuffers "github.com/google/flatbuffers/go"
)

// Force usage of time and protocol to avoid unused import error
var _ = time.Now
var _ = protocol.Bool{}

var (
	asyncBatcher   = server.NewAsyncBatcher()
	chunkManager   = server.NewChunkManager()
	commandBatcher = server.NewCommandBatcher()
)

func ScheduleSet(r *protocol.Range, v *protocol.Any) {
	commandBatcher.ScheduleSet(r, v)
}

func ScheduleFormat(r *protocol.Range, fmtStr string) {
	commandBatcher.ScheduleFormat(r, fmtStr)
}

func Serve(handler XllService) {
	// Parse command line flags to get SHM name
	shmName := flag.String("xll-shm", "{{.ProjectName}}", "Shared Memory Name")
	flag.Parse()

    if _, err := server.InitLog("{{.Logging.Dir}}", "{{.Logging.Level}}", "{{.ProjectName}}"); err != nil {
        fmt.Printf("Failed to initialize logger: %v\n", err)
    }

    log.Info("Connecting to SHM", "name", *shmName)
    client, err := server.ConnectSHM(*shmName)
    if err != nil {
        log.Error("Failed to connect to SHM", "error", err)
        panic(err)
    }
    defer client.Close()

	var refCacheMutex sync.RWMutex
	refCache := make(map[string][]byte)

	asyncBatcher.StartWorker(func(batch []server.PendingAsyncResult) {
		server.FlushAsyncBatch(batch, client)
	})

	{{range .Functions}}
	{{if .Timeout}}
	timeout_{{.Name}}, _ := time.ParseDuration("{{.Timeout}}")
	{{end}}
	{{end}}

	workerCount := runtime.NumCPU()
	if n := {{.ServerWorkers}}; n > 0 {
		workerCount = n
	}

	jobQueue := make(chan func(), workerCount)
	for i := 0; i < workerCount; i++ {
		go func() {
			defer func() {
				if r := recover(); r != nil {
					log.Error("Worker died unexpectedly", "error", r, "stack", string(debug.Stack()))
				}
			}()
			for job := range jobQueue {
				job()
			}
		}()
	}

	var dispatch func(data []byte, respBuf []byte, mType shm.MsgType) (int32, shm.MsgType)
	dispatch = func(data []byte, respBuf []byte, mType shm.MsgType) (int32, shm.MsgType) {
             builder, releaseBuilder := server.GetBuilder(respBuf)
             defer releaseBuilder()

             switch uint32(mType) {
             case server.MsgCalculationEnded:
                refCacheMutex.Lock()
                refCache = make(map[string][]byte)
                refCacheMutex.Unlock()

                {{if hasEvent "CalculationEnded" .Events}}
                var wg sync.WaitGroup
                wg.Add(1)
                go func() {
                    defer wg.Done()
                    defer func() {
                        if r := recover(); r != nil {
                            log.Error("Panic in OnCalculationEnded", "error", r, "stack", string(debug.Stack()))
                        }
                    }()
                    if err := handler.OnCalculationEnded(context.Background()); err != nil {
                        log.Error("Event handler OnCalculationEnded failed", "error", err)
                    }
                }()
                wg.Wait()
                {{end}}

                builder.Reset()
                respBytes := commandBatcher.FlushCommands(builder)
                if len(respBytes) > 0 {
                    // Zero-Copy Return
                    if cap(builder.Bytes) == cap(respBuf) && len(respBytes) <= len(respBuf) {
                        return -int32(len(respBytes)), server.MsgCalculationEnded
                    }

                    if len(respBytes) > len(respBuf) {
                        log.Warn("CalculationEnded response too large", "size", len(respBytes))
                        return 0, 0
                    }
                    copy(respBuf, respBytes)
                    return int32(len(respBytes)), server.MsgCalculationEnded
                }
                return 0, 0

             case server.MsgCalculationCanceled:
                commandBatcher.Clear()

                {{if hasEvent "CalculationCanceled" .Events}}
                ctx := context.Background()
                go func() {
                    defer func() {
                        if r := recover(); r != nil {
                            log.Error("Panic in OnCalculationCanceled", "error", r, "stack", string(debug.Stack()))
                        }
                    }()
                    if err := handler.OnCalculationCanceled(ctx); err != nil {
                        log.Error("Event handler OnCalculationCanceled failed", "error", err)
                    }
                }()
                {{end}}
                return 0, 0

             case server.MsgSetRefCache:
                reqObj := protocol.GetRootAsSetRefCacheRequest(data, 0)
                key := string(reqObj.Key())
                reqCopy := make([]byte, len(data))
                copy(reqCopy, data)

                refCacheMutex.Lock()
                refCache[key] = reqCopy
                refCacheMutex.Unlock()

                payload := server.BuildAckResponse(builder, 0, true)

                log.Debug("ACK sent", "func", "SetRefCache")

                if cap(builder.Bytes) == cap(respBuf) && len(payload) <= len(respBuf) {
                    return -int32(len(payload)), server.MsgAck
                }
                if len(payload) > len(respBuf) { return 0, 0 }
                copy(respBuf, payload)
                return int32(len(payload)), server.MsgAck

             case server.MsgAck:
                reqObj := protocol.GetRootAsAck(data, 0)
                id := reqObj.Id()

                const chunkSize = 950 * 1024
                chunkData, msgType, totalSize, offset, found := chunkManager.GetNextChunk(id, chunkSize)

                if !found {
                    return 0, 0
                }

                if len(chunkData) == 0 {
                    return 0, 0
                }

                payload := server.BuildChunkResponse(builder, chunkData, id, totalSize, offset, msgType)

                if cap(builder.Bytes) == cap(respBuf) && len(payload) <= len(respBuf) {
                    return -int32(len(payload)), server.MsgChunk
                }
                if len(payload) > len(respBuf) { return 0, 0 }
                copy(respBuf, payload)
                return int32(len(payload)), server.MsgChunk

             case server.MsgChunk:
                reqObj := protocol.GetRootAsChunk(data, 0)
                id := reqObj.Id()
                total := int(reqObj.TotalSize())
                offset := int(reqObj.Offset())
                dataLen := reqObj.DataLength()

                buf := chunkManager.GetChunkBuffer(id, total)

                buf.Mutex.Lock()
                if offset + dataLen <= len(buf.Data) {
                    copy(buf.Data[offset:], reqObj.DataBytes())
                    buf.Received += dataLen
                }
                isComplete := buf.Received >= buf.TotalSize
                buf.Mutex.Unlock()

                if isComplete {
                    chunkManager.RemoveChunkBuffer(id)
                    payloadMsgType := reqObj.MsgType()
                    return dispatch(buf.Data, respBuf, shm.MsgType(payloadMsgType))
                }

                payload := server.BuildAckResponse(builder, id, true)

                if cap(builder.Bytes) == cap(respBuf) && len(payload) <= len(respBuf) {
                    return -int32(len(payload)), server.MsgChunk
                }
                if len(payload) > len(respBuf) { return 0, 0 }
                copy(respBuf, payload)
                return int32(len(payload)), server.MsgChunk

{{range .Events}}
             {{if and (ne .Type "CalculationEnded") (ne .Type "CalculationCanceled")}}
             case {{lookupEventId .Type}}:
                ctx := context.Background()
                select {
                case jobQueue <- func() {
                    defer func() {
                        if r := recover(); r != nil {
                            log.Error("Panic in Event Handler {{.Name}}", "error", r, "stack", string(debug.Stack()))
                        }
                    }()
                    if err := handler.{{.Name}}(ctx); err != nil {
                        log.Error("Event handler {{.Name}} failed", "error", err)
                    }
                }:
                default:
                    log.Warn("Event dropped due to server load", "event", "{{.Name}}")
                }
                return 0, 0
             {{end}}
{{end}}

{{range $i, $fn := .Functions}}             case {{add (MsgUserStart) $i}}: // {{.Name}}
                {{if .Timeout}}
                ctx, cancel := context.WithTimeout(context.Background(), timeout_{{.Name}})
                {{else}}
                ctx := context.Background()
                cancel := func() {}
                {{end}}

                {{if .Async}}
                reqCopy := make([]byte, len(data))
                copy(reqCopy, data)
                select {
                case jobQueue <- func() {
                    defer func() {
                        if r := recover(); r != nil {
                            log.Error("Panic in Async Job {{.Name}}", "error", r, "stack", string(debug.Stack()))
                        }
                        cancel()
                    }()
                    handle{{.Name}}(ctx, reqCopy, nil, handler, nil, client, mType, refCache, &refCacheMutex)
                }:
                default:
                    log.Warn("Async worker pool full, returning Busy error", "func", "{{.Name}}")
                    // Fast-fail
                    reqObj := ipc.GetRootAs{{.Name}}Request(reqCopy, 0)
                    h := reqObj.AsyncHandleBytes()
                    queueAsyncResult(h, nil, protocol.AnyValue(0), "Server Busy")
                }

                payload := server.BuildAckResponse(builder, 0, true)

                if cap(builder.Bytes) == cap(respBuf) && len(payload) <= len(respBuf) {
                    return -int32(len(payload)), server.MsgAck
                }
                if len(payload) > len(respBuf) { return 0, 0 }
                copy(respBuf, payload)
                return int32(len(payload)), server.MsgAck
                {{else}}
                defer cancel()
                len, respId := handle{{.Name}}(ctx, data, respBuf, handler, builder, client, mType, refCache, &refCacheMutex)
                return len, respId
                {{end}}
{{end}}
             default:
                return 0, 0
             }
	}

	client.Handle(dispatch)

	client.Start()
	client.Wait()
}

// ... handle functions ...
{{range $i, $fn := .Functions}}
func handle{{.Name}}(ctx context.Context, req []byte, respBuf []byte, handler XllService, b *flatbuffers.Builder, client *shm.Client, msgType shm.MsgType, refCache map[string][]byte, refCacheMutex *sync.RWMutex) (int32, shm.MsgType) {
	request := ipc.GetRootAs{{.Name}}Request(req, 0)
	_ = request

	{{if .Caller}}
	caller := request.Caller(nil)
	{{end}}

	{{if .Async}}
	handle := request.AsyncHandleBytes()

	log.Debug("Async function start", "func", "{{.Name}}")

	if ctx.Err() != nil {
		queueAsyncResult(handle, nil, protocol.AnyValue(0), ctx.Err().Error())
		return 0, 0
	}

	func() {
		defer func() {
			if r := recover(); r != nil {
				stack := debug.Stack()
				log.Error("Panic in async handler {{.Name}}", "error", r, "stack", string(stack))
				queueAsyncResult(handle, nil, protocol.AnyValue(0), fmt.Sprintf("panic: %v", r))
			}
			log.Debug("Async function end", "func", "{{.Name}}")
		}()

		{{range .Args}}
		{{if eq .Type "string"}}
		arg_{{.Name}} := string(request.{{.Name|capitalize}}())
		{{else if eq .Type "int?"}}
		var arg_{{.Name}} *int32
		if v := request.{{.Name|capitalize}}(nil); v != nil {
			val := v.Val()
			arg_{{.Name}} = &val
		}
		{{else if eq .Type "float?"}}
		var arg_{{.Name}} *float64
		if v := request.{{.Name|capitalize}}(nil); v != nil {
			val := v.Val()
			arg_{{.Name}} = &val
		}
		{{else if eq .Type "bool?"}}
		var arg_{{.Name}} *bool
		if v := request.{{.Name|capitalize}}(nil); v != nil {
			val := v.Val()
			arg_{{.Name}} = &val
		}
		{{else if eq .Type "range"}}
		arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
		{{else if eq .Type "grid"}}
		arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
		{{else if eq .Type "numgrid"}}
		arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
		{{else if eq .Type "any"}}
		var arg_{{.Name}} *protocol.Any
		arg_{{.Name}}_raw := request.{{.Name|capitalize}}(nil)
		if arg_{{.Name}}_raw != nil {
			if arg_{{.Name}}_raw.ValType() == protocol.AnyValueRefCache {
				var rc protocol.RefCache
				init := new(flatbuffers.Table)
				if arg_{{.Name}}_raw.Val(init) {
					rc.Init(init.Bytes, init.Pos)
					key := string(rc.Key())
					refCacheMutex.RLock()
					if data, ok := refCache[key]; ok {
						cacheReq := protocol.GetRootAsSetRefCacheRequest(data, 0)
						arg_{{.Name}} = cacheReq.Val(nil)
					} else {
						arg_{{.Name}} = arg_{{.Name}}_raw
					}
					refCacheMutex.RUnlock()
				}
			} else {
				arg_{{.Name}} = arg_{{.Name}}_raw
			}
		}
		{{else}}
		arg_{{.Name}} := request.{{.Name|capitalize}}()
		{{end}}
		{{end}}

		log.Debug("Processing async request", "func", "{{.Name}}")

		res, err := handler.{{.Name}}(ctx{{range .Args}}, arg_{{.Name}}{{end}}{{if .Caller}}, caller{{end}})

		if err != nil {
			queueAsyncResult(handle, nil, protocol.AnyValue(0), err.Error())
		} else {
			{{if eq .Return "string"}}
			queueAsyncResult(handle, res, protocol.AnyValueStr, "")
			{{else if eq .Return "int"}}
			queueAsyncResult(handle, res, protocol.AnyValueInt, "")
			{{else if eq .Return "int?"}}
			if res != nil {
				queueAsyncResult(handle, *res, protocol.AnyValueInt, "")
			} else {
				queueAsyncResult(handle, nil, protocol.AnyValueNil, "")
			}
			{{else if eq .Return "float"}}
			queueAsyncResult(handle, res, protocol.AnyValueNum, "")
			{{else if eq .Return "float?"}}
			if res != nil {
				queueAsyncResult(handle, *res, protocol.AnyValueNum, "")
			} else {
				queueAsyncResult(handle, nil, protocol.AnyValueNil, "")
			}
			{{else if eq .Return "bool"}}
			queueAsyncResult(handle, res, protocol.AnyValueBool, "")
			{{else if eq .Return "bool?"}}
			if res != nil {
				queueAsyncResult(handle, *res, protocol.AnyValueBool, "")
			} else {
				queueAsyncResult(handle, nil, protocol.AnyValueNil, "")
			}
			{{end}}
		}
	}()

	return 0, 0
	{{else}}
	var res {{lookupGoType .Return}}
	var err error

	log.Debug("Sync function start", "func", "{{.Name}}")

	func() {
		defer func() {
			if r := recover(); r != nil {
				stack := debug.Stack()
				log.Error("Panic in sync handler {{.Name}}", "error", r, "stack", string(stack))
				err = fmt.Errorf("panic: %v", r)
			}
			log.Debug("Sync function end", "func", "{{.Name}}")
		}()

		{{range .Args}}
		{{if eq .Type "string"}}
		arg_{{.Name}} := string(request.{{.Name|capitalize}}())
		{{else if eq .Type "int?"}}
		var arg_{{.Name}} *int32
		if v := request.{{.Name|capitalize}}(nil); v != nil {
			val := v.Val()
			arg_{{.Name}} = &val
		}
		{{else if eq .Type "float?"}}
		var arg_{{.Name}} *float64
		if v := request.{{.Name|capitalize}}(nil); v != nil {
			val := v.Val()
			arg_{{.Name}} = &val
		}
		{{else if eq .Type "bool?"}}
		var arg_{{.Name}} *bool
		if v := request.{{.Name|capitalize}}(nil); v != nil {
			val := v.Val()
			arg_{{.Name}} = &val
		}
		{{else if eq .Type "range"}}
		arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
		{{else if eq .Type "grid"}}
		arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
		{{else if eq .Type "numgrid"}}
		arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
		{{else if eq .Type "any"}}
		var arg_{{.Name}} *protocol.Any
		arg_{{.Name}}_raw := request.{{.Name|capitalize}}(nil)
		if arg_{{.Name}}_raw != nil {
			if arg_{{.Name}}_raw.ValType() == protocol.AnyValueRefCache {
				var rc protocol.RefCache
				init := new(flatbuffers.Table)
				if arg_{{.Name}}_raw.Val(init) {
					rc.Init(init.Bytes, init.Pos)
					key := string(rc.Key())
					refCacheMutex.RLock()
					if data, ok := refCache[key]; ok {
						cacheReq := protocol.GetRootAsSetRefCacheRequest(data, 0)
						arg_{{.Name}} = cacheReq.Val(nil)
					} else {
						arg_{{.Name}} = arg_{{.Name}}_raw
					}
					refCacheMutex.RUnlock()
				}
			} else {
				arg_{{.Name}} = arg_{{.Name}}_raw
			}
		}
		{{else}}
		arg_{{.Name}} := request.{{.Name|capitalize}}()
		{{end}}
		{{end}}

		res, err = handler.{{.Name}}(ctx{{range .Args}}, arg_{{.Name}}{{end}}{{if .Caller}}, caller{{end}})
	}()

	b.Reset()
	var errOffset flatbuffers.UOffsetT
	if err != nil {
		errOffset = b.CreateString(err.Error())
	}

	{{if eq .Return "string"}}
	var resOffset flatbuffers.UOffsetT
	if err == nil {
		resOffset = b.CreateString(res)
	}
	{{else if eq .Return "int?"}}
	var resOffset flatbuffers.UOffsetT
	if err == nil && res != nil {
		protocol.IntStart(b)
		protocol.IntAddVal(b, *res)
		resOffset = protocol.IntEnd(b)
	}
	{{else if eq .Return "float?"}}
	var resOffset flatbuffers.UOffsetT
	if err == nil && res != nil {
		protocol.NumStart(b)
		protocol.NumAddVal(b, *res)
		resOffset = protocol.NumEnd(b)
	}
	{{else if eq .Return "bool?"}}
	var resOffset flatbuffers.UOffsetT
	if err == nil && res != nil {
		protocol.BoolStart(b)
		protocol.BoolAddVal(b, *res)
		resOffset = protocol.BoolEnd(b)
	}
	{{end}}

	ipc.{{.Name}}ResponseStart(b)
	if err != nil {
		ipc.{{.Name}}ResponseAddError(b, errOffset)
	} else {
		{{if or (eq .Return "string") (eq .Return "int?") (eq .Return "float?") (eq .Return "bool?")}}
		if resOffset > 0 {
			ipc.{{.Name}}ResponseAddResult(b, resOffset)
		}
		{{else}}
		ipc.{{.Name}}ResponseAddResult(b, res)
		{{end}}
	}
	root := ipc.{{.Name}}ResponseEnd(b)
	b.Finish(root)

	// Zero-Copy Return
	// cap(b.Bytes) == cap(respBuf) implies it is still the SHM buffer.
	// If so, data is end-aligned and we return negative size.
	payload := b.FinishedBytes()
	if cap(b.Bytes) == cap(respBuf) && len(payload) <= len(respBuf) {
		return -int32(len(payload)), msgType
	}

	if len(payload) > len(respBuf) {
		// Chunking needed
		transferId := uint64(rand.Int63())

        out := &server.OutgoingChunk{
            Data:       make([]byte, len(payload)),
            Id:         transferId,
            MsgType:    uint32(msgType),
            LastAccess: time.Now(),
        }
		copy(out.Data, payload)
        chunkManager.AddOutgoingChunk(transferId, out)

		const chunkSize = 950 * 1024
		currentSize := chunkSize
		if len(out.Data) < chunkSize {
			currentSize = len(out.Data)
		}

		payload = server.BuildChunkResponse(b, out.Data[0:currentSize], transferId, len(out.Data), 0, uint32(msgType))

		out.Offset = currentSize

		if len(payload) > len(respBuf) {
			return 0, 0 // Fatal: Chunk header overhead made it > 1MB?
		}
		copy(respBuf, payload)
		return int32(len(payload)), server.MsgChunk
	}
	copy(respBuf, payload)
	return int32(len(payload)), msgType
	{{end}}
}

{{end}}

{{if hasAsync .Functions}}
func queueAsyncResult(handle []byte, val interface{}, valType protocol.AnyValue, errStr string) {
	asyncBatcher.QueueResult(handle, val, valType, errStr)
}
{{end}}
