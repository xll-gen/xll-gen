// Code generated by xll-gen {{.Version}}. DO NOT EDIT.
package {{.Package}}

import (
	"context"
	"fmt"
	"log/slog"
	"math/rand"
	"os"
	"strings"
	"sync"
	"time"
	"runtime"
	"runtime/debug"
	"{{.ModName}}/generated/ipc"
	"{{.ModName}}/generated/ipc/types"
	"github.com/xll-gen/xll-gen/pkg/log"
	"github.com/xll-gen/xll-gen/pkg/algo"
	"github.com/xll-gen/xll-gen/pkg/server"
	"github.com/xll-gen/shm/go"
	flatbuffers "github.com/google/flatbuffers/go"
)

// Force usage of time and ipc/types to avoid unused import error
var _ = time.Now
var _ = types.Bool{}

var (
	cmdQueueLock sync.Mutex
	cmdQueue     []server.QueuedCommand
)

var (
	asyncBatcher = server.NewAsyncBatcher()
	chunkManager = server.NewChunkManager()

	// Builder Pool to reduce GC pressure
	builderPool = sync.Pool{
		New: func() interface{} {
			return flatbuffers.NewBuilder(1024)
		},
	}

	// Heap Builder Pool for outgoing messages (retains buffer capacity)
	heapBuilderPool = sync.Pool{
		New: func() interface{} {
			return flatbuffers.NewBuilder(1024)
		},
	}
)

var (
	bufferedSets      = make(map[string]map[algo.Cell]server.ScalarValue)
	bufferedFormats   = make(map[string]map[algo.Cell]string)
	bufferLock        sync.Mutex
)

func ScheduleSet(r *types.Range, v *types.Any) {
	scalar, ok := toScalar(v)
	if ok {
		sheet := string(r.SheetName())
		bufferLock.Lock()
		if bufferedSets[sheet] == nil {
			bufferedSets[sheet] = make(map[algo.Cell]server.ScalarValue)
		}

		l := r.RefsLength()
		for i := 0; i < l; i++ {
			var rect types.Rect
			if r.Refs(&rect, i) {
				for row := rect.RowFirst(); row <= rect.RowLast(); row++ {
					for col := rect.ColFirst(); col <= rect.ColLast(); col++ {
						bufferedSets[sheet][algo.Cell{Row: row, Col: col}] = scalar
					}
				}
			}
		}
		bufferLock.Unlock()
		return
	}

	flushBuffers()

	b := flatbuffers.NewBuilder(0)
	rOff := cloneRange(b, r)
	vOff := cloneAny(b, v)

	ipc.SetCommandStart(b)
	ipc.SetCommandAddTarget(b, rOff)
	ipc.SetCommandAddValue(b, vOff)
	root := ipc.SetCommandEnd(b)
	b.Finish(root)

	cmdQueueLock.Lock()
	cmdQueue = append(cmdQueue, server.QueuedCommand{CmdType: 0, Data: b.FinishedBytes()})
	cmdQueueLock.Unlock()
}

func ScheduleFormat(r *types.Range, fmtStr string) {
	sheet := string(r.SheetName())
	bufferLock.Lock()
	if bufferedFormats[sheet] == nil {
		bufferedFormats[sheet] = make(map[algo.Cell]string)
	}

	l := r.RefsLength()
	for i := 0; i < l; i++ {
		var rect types.Rect
		if r.Refs(&rect, i) {
			for row := rect.RowFirst(); row <= rect.RowLast(); row++ {
				for col := rect.ColFirst(); col <= rect.ColLast(); col++ {
					bufferedFormats[sheet][algo.Cell{Row: row, Col: col}] = fmtStr
				}
			}
		}
	}
	bufferLock.Unlock()
}

func flushBuffers() {
	bufferLock.Lock()
	defer bufferLock.Unlock()

	// Process Sets
	for sheet, cells := range bufferedSets {
		byVal := make(map[server.ScalarValue][]algo.Cell)
		for cell, val := range cells {
			byVal[val] = append(byVal[val], cell)
		}

		for val, cellList := range byVal {
			rects := algo.GreedyMesh(cellList)

			// Chunk by 32
			for i := 0; i < len(rects); i += 32 {
				end := i + 32
				if end > len(rects) { end = len(rects) }
				batch := rects[i:end]

				cmdQueueLock.Lock()
				cmdQueue = append(cmdQueue, server.QueuedCommand{
					CmdType:   0,
					Sheet:     sheet,
					Rects:     batch,
					ScalarVal: val,
				})
				cmdQueueLock.Unlock()
			}
		}
		delete(bufferedSets, sheet)
	}

	// Process Formats
	for sheet, cells := range bufferedFormats {
		byFmt := make(map[string][]algo.Cell)
		for cell, fmt := range cells {
			byFmt[fmt] = append(byFmt[fmt], cell)
		}

		for fmt, cellList := range byFmt {
			rects := algo.GreedyMesh(cellList)

			for i := 0; i < len(rects); i += 32 {
				end := i + 32
				if end > len(rects) { end = len(rects) }
				batch := rects[i:end]

				cmdQueueLock.Lock()
				cmdQueue = append(cmdQueue, server.QueuedCommand{
					CmdType:   1,
					Sheet:     sheet,
					Rects:     batch,
					FormatStr: fmt,
				})
				cmdQueueLock.Unlock()
			}
		}
		delete(bufferedFormats, sheet)
	}
}

func toScalar(v *types.Any) (server.ScalarValue, bool) {
	if v == nil { return server.ScalarValue{}, false }
	var tbl flatbuffers.Table
	if !v.Val(&tbl) { return server.ScalarValue{}, false }

	switch v.ValType() {
	case types.AnyValueInt:
		var t types.Int; t.Init(tbl.Bytes, tbl.Pos)
		return server.ScalarValue{Type: server.AnyValueInt, Int: t.Val()}, true
	case types.AnyValueNum:
		var t types.Num; t.Init(tbl.Bytes, tbl.Pos)
		return server.ScalarValue{Type: server.AnyValueNum, Num: t.Val()}, true
	case types.AnyValueBool:
		var t types.Bool; t.Init(tbl.Bytes, tbl.Pos)
		return server.ScalarValue{Type: server.AnyValueBool, Bool: t.Val()}, true
	case types.AnyValueStr:
		var t types.Str; t.Init(tbl.Bytes, tbl.Pos)
		return server.ScalarValue{Type: server.AnyValueStr, Str: string(t.Val())}, true
	case types.AnyValueErr:
		var t types.Err; t.Init(tbl.Bytes, tbl.Pos)
		return server.ScalarValue{Type: server.AnyValueErr, Err: int16(t.Val())}, true
	}
	return server.ScalarValue{}, false
}

func createScalarAny(b *flatbuffers.Builder, val server.ScalarValue) flatbuffers.UOffsetT {
	var uOff flatbuffers.UOffsetT
	switch val.Type {
	case server.AnyValueInt:
		types.IntStart(b)
		types.IntAddVal(b, val.Int)
		uOff = types.IntEnd(b)
	case server.AnyValueNum:
		types.NumStart(b)
		types.NumAddVal(b, val.Num)
		uOff = types.NumEnd(b)
	case server.AnyValueBool:
		types.BoolStart(b)
		types.BoolAddVal(b, val.Bool)
		uOff = types.BoolEnd(b)
	case server.AnyValueStr:
		sOff := b.CreateString(val.Str)
		types.StrStart(b)
		types.StrAddVal(b, sOff)
		uOff = types.StrEnd(b)
	case server.AnyValueErr:
		types.ErrStart(b)
		types.ErrAddVal(b, types.XlError(val.Err))
		uOff = types.ErrEnd(b)
	}

	types.AnyStart(b)
	types.AnyAddValType(b, types.AnyValue(val.Type))
	types.AnyAddVal(b, uOff)
	return types.AnyEnd(b)
}

func flushAsyncBatch(batch []server.PendingAsyncResult, client *shm.Client) {
	if len(batch) == 0 {
		return
	}

	b := heapBuilderPool.Get().(*flatbuffers.Builder)
	b.Reset()
	defer heapBuilderPool.Put(b)

	resultOffsets := make([]flatbuffers.UOffsetT, len(batch))

	for i, res := range batch {
		var anyOff flatbuffers.UOffsetT
		var errOff flatbuffers.UOffsetT

		if res.Err != "" {
			errOff = b.CreateString(res.Err)
		} else {
			// Build Any Table
			var uOff flatbuffers.UOffsetT
			switch res.ValType {
			case server.AnyValueInt:
				types.IntStart(b)
				types.IntAddVal(b, res.Val.(int32))
				uOff = types.IntEnd(b)
			case server.AnyValueNum:
				types.NumStart(b)
				types.NumAddVal(b, res.Val.(float64))
				uOff = types.NumEnd(b)
			case server.AnyValueBool:
				types.BoolStart(b)
				types.BoolAddVal(b, res.Val.(bool))
				uOff = types.BoolEnd(b)
			case server.AnyValueStr:
				sOff := b.CreateString(res.Val.(string))
				types.StrStart(b)
				types.StrAddVal(b, sOff)
				uOff = types.StrEnd(b)
			case server.AnyValueNil:
				types.NilStart(b)
				uOff = types.NilEnd(b)
			}

			types.AnyStart(b)
			types.AnyAddValType(b, types.AnyValue(res.ValType))
			types.AnyAddVal(b, uOff)
			anyOff = types.AnyEnd(b)
		}

		ipc.AsyncResultStart(b)
		ipc.AsyncResultAddHandle(b, res.Handle)
		if errOff > 0 {
			ipc.AsyncResultAddError(b, errOff)
		} else {
			ipc.AsyncResultAddResult(b, anyOff)
		}
		resultOffsets[i] = ipc.AsyncResultEnd(b)
	}

	ipc.BatchAsyncResponseStartResultsVector(b, len(resultOffsets))
	for i := len(resultOffsets) - 1; i >= 0; i-- {
		b.PrependUOffsetT(resultOffsets[i])
	}
	resultsVec := b.EndVector(len(resultOffsets))

	ipc.BatchAsyncResponseStart(b)
	ipc.BatchAsyncResponseAddResults(b, resultsVec)
	root := ipc.BatchAsyncResponseEnd(b)
	b.Finish(root)

	// Send Batch Message
	msgBytes := b.FinishedBytes()

	// Chunking Logic
	const maxPayload = 950 * 1024 // 1MB - overhead
	if len(msgBytes) > maxPayload {
		sendChunkedAsync(msgBytes, client)
		return
	}

	// We implement a short retry loop to handle transient buffer fullness.
	var err error
	for i := 0; i < 10; i++ {
		if _, err = client.SendGuestCall(msgBytes, server.MsgBatchAsyncResponse); err == nil {
			return
		}
		// Backoff: 5ms, 10ms, ... 2.5s max total wait
		time.Sleep(5 * time.Millisecond * time.Duration(1<<i))
	}

	if err != nil {
		log.Error("Error sending batch async response after retries", "error", err)
	}
}

func sendChunkedAsync(data []byte, client *shm.Client) {
	transferId := uint64(rand.Int63())
	total := len(data)
	offset := 0
	const chunkSize = 950 * 1024

	for offset < total {
		end := offset + chunkSize
		if end > total {
			end = total
		}
		chunkData := data[offset:end]

		b := heapBuilderPool.Get().(*flatbuffers.Builder)
		b.Reset()

		dataOff := b.CreateByteVector(chunkData)
		ipc.ChunkStart(b)
		ipc.ChunkAddId(b, transferId)
		ipc.ChunkAddTotalSize(b, uint32(total))
		ipc.ChunkAddOffset(b, uint32(offset))
		ipc.ChunkAddData(b, dataOff)
		ipc.ChunkAddMsgType(b, server.MsgBatchAsyncResponse)
		root := ipc.ChunkEnd(b)
		b.FinishWithFileIdentifier(root, []byte("XCHN"))

		payload := b.FinishedBytes()

		// Send Chunk with Retry
		var err error
		sent := false
		for i := 0; i < 10; i++ {
			if _, err = client.SendGuestCall(payload, server.MsgChunk); err == nil {
				sent = true
				break
			}
			time.Sleep(5 * time.Millisecond * time.Duration(1<<i))
		}

		heapBuilderPool.Put(b)

		if !sent {
			log.Error("Failed to send async chunk", "error", err, "id", transferId, "offset", offset)
			return // Abort transfer
		}

		offset = end
	}
}

func Serve(handler XllService) {
	// Initialize Logger
	if err := log.Init("{{.Logging.Path}}", "{{.Logging.Level}}"); err != nil {
		fmt.Printf("Failed to initialize logger: %v\n", err)
	}
	shm.SetLogger(slog.Default())

	name := "{{.ProjectName}}"
	for _, arg := range os.Args {
		if strings.HasPrefix(arg, "-xll-shm=") {
			name = strings.TrimPrefix(arg, "-xll-shm=")
		}
	}

	client, err := shm.Connect(shm.ClientConfig{ShmName: name})
	if err != nil {
		log.Error("Failed to connect to SHM", "error", err)
		panic(fmt.Errorf("failed to connect to SHM: %w", err))
	}
	defer client.Close()

	// Global Ref Cache
	var refCacheMutex sync.RWMutex
	refCache := make(map[string][]byte)

	// Start Async Worker
	asyncBatcher.StartWorker(func(batch []server.PendingAsyncResult) {
		flushAsyncBatch(batch, client)
	})

	// Configuration
	{{range .Functions}}
	{{if .Timeout}}
	timeout_{{.Name}}, _ := time.ParseDuration("{{.Timeout}}")
	{{end}}
	{{end}}

	workerCount := runtime.NumCPU()
	if n := {{.ServerWorkers}}; n > 0 {
		workerCount = n
	}

	// Worker Pool
	jobQueue := make(chan func(), workerCount)
	for i := 0; i < workerCount; i++ {
		go func() {
			for job := range jobQueue {
				job()
			}
		}()
	}

	var dispatch func(data []byte, respBuf []byte, mType shm.MsgType) (int32, shm.MsgType)
	dispatch = func(data []byte, respBuf []byte, mType shm.MsgType) (int32, shm.MsgType) {
             builder := builderPool.Get().(*flatbuffers.Builder)
             if respBuf != nil && cap(respBuf) > 0 {
                 builder.Bytes = respBuf
             }
             builder.Reset()
             // Safety: Detach SHM buffer before returning to pool to prevent corruption
             defer func() {
                 builder.Bytes = nil
                 builderPool.Put(builder)
             }()

             switch uint32(mType) {
             case server.MsgCalculationEnded:
                refCacheMutex.Lock()
                refCache = make(map[string][]byte)
                refCacheMutex.Unlock()

                {{if hasEvent "CalculationEnded" .Events}}
                var wg sync.WaitGroup
                wg.Add(1)
                jobQueue <- func() {
                    defer wg.Done()
                    if err := handler.OnCalculationEnded(context.Background()); err != nil {
                        log.Error("Event handler OnCalculationEnded failed", "error", err)
                    }
                }
                wg.Wait()
                {{end}}

                builder.Reset()
                respBytes := flushCommands(builder)
                if len(respBytes) > 0 {
                    // Zero-Copy Return (Negative Size)
                    if cap(builder.Bytes) == cap(respBuf) && len(respBytes) <= len(respBuf) {
                        return -int32(len(respBytes)), server.MsgCalculationEnded
                    }

                    if len(respBytes) > len(respBuf) {
                        log.Warn("CalculationEnded response too large", "size", len(respBytes))
                        return 0, 0
                    }
                    copy(respBuf, respBytes)
                    return int32(len(respBytes)), server.MsgCalculationEnded
                }
                return 0, 0

             case server.MsgCalculationCanceled:
                cmdQueueLock.Lock()
                cmdQueue = nil
                cmdQueueLock.Unlock()
                bufferLock.Lock()
                bufferedSets = make(map[string]map[algo.Cell]server.ScalarValue)
                bufferedFormats = make(map[string]map[algo.Cell]string)
                bufferLock.Unlock()

                {{if hasEvent "CalculationCanceled" .Events}}
                ctx := context.Background()
                jobQueue <- func() {
                    if err := handler.OnCalculationCanceled(ctx); err != nil {
                        log.Error("Event handler OnCalculationCanceled failed", "error", err)
                    }
                }
                {{end}}
                return 0, 0

             case server.MsgSetRefCache:
                reqObj := ipc.GetRootAsSetRefCacheRequest(data, 0)
                key := string(reqObj.Key())
                reqCopy := make([]byte, len(data))
                copy(reqCopy, data)

                refCacheMutex.Lock()
                refCache[key] = reqCopy
                refCacheMutex.Unlock()

                ipc.AckStart(builder)
                ipc.AckAddOk(builder, true)
                root := ipc.AckEnd(builder)
                builder.Finish(root)

                payload := builder.FinishedBytes()
                if cap(builder.Bytes) == cap(respBuf) && len(payload) <= len(respBuf) {
                    return -int32(len(payload)), server.MsgAck
                }
                if len(payload) > len(respBuf) { return 0, 0 }
                copy(respBuf, payload)
                return int32(len(payload)), server.MsgAck

             case server.MsgAck:
                reqObj := ipc.GetRootAsAck(data, 0)
                id := reqObj.Id()

                const chunkSize = 950 * 1024
                chunkData, msgType, totalSize, offset, found := chunkManager.GetNextChunk(id, chunkSize)

                if !found {
                    return 0, 0
                }

                if len(chunkData) == 0 {
                    return 0, 0
                }

                builder.Reset()
                dataOff := builder.CreateByteVector(chunkData)
                ipc.ChunkStart(builder)
                ipc.ChunkAddId(builder, id)
                ipc.ChunkAddTotalSize(builder, uint32(totalSize))
                ipc.ChunkAddOffset(builder, uint32(offset))
                ipc.ChunkAddData(builder, dataOff)
                ipc.ChunkAddMsgType(builder, msgType)
                root := ipc.ChunkEnd(builder)
                builder.FinishWithFileIdentifier(root, []byte("XCHN"))

                payload := builder.FinishedBytes()
                if cap(builder.Bytes) == cap(respBuf) && len(payload) <= len(respBuf) {
                    return -int32(len(payload)), server.MsgChunk
                }
                if len(payload) > len(respBuf) { return 0, 0 }
                copy(respBuf, payload)
                return int32(len(payload)), server.MsgChunk

             case server.MsgChunk:
                reqObj := ipc.GetRootAsChunk(data, 0)
                id := reqObj.Id()
                total := int(reqObj.TotalSize())
                offset := int(reqObj.Offset())
                dataLen := reqObj.DataLength()

                buf := chunkManager.GetChunkBuffer(id, total)

                buf.Mutex.Lock()
                if offset + dataLen <= len(buf.Data) {
                    copy(buf.Data[offset:], reqObj.DataBytes())
                    buf.Received += dataLen
                }
                isComplete := buf.Received >= buf.TotalSize
                buf.Mutex.Unlock()

                if isComplete {
                    chunkManager.RemoveChunkBuffer(id)
                    payloadMsgType := reqObj.MsgType()
                    return dispatch(buf.Data, respBuf, shm.MsgType(payloadMsgType))
                }

                ipc.AckStart(builder)
                ipc.AckAddId(builder, id)
                ipc.AckAddOk(builder, true)
                root := ipc.AckEnd(builder)
                builder.Finish(root)

                payload := builder.FinishedBytes()
                if cap(builder.Bytes) == cap(respBuf) && len(payload) <= len(respBuf) {
                    return -int32(len(payload)), server.MsgChunk
                }
                if len(payload) > len(respBuf) { return 0, 0 }
                copy(respBuf, payload)
                return int32(len(payload)), server.MsgChunk

{{range .Events}}
             {{if and (ne .Type "CalculationEnded") (ne .Type "CalculationCanceled")}}
             case {{lookupEventId .Type}}:
                ctx := context.Background()
                jobQueue <- func() {
                    if err := handler.{{.Name}}(ctx); err != nil {
                        log.Error("Event handler {{.Name}} failed", "error", err)
                    }
                }
                return 0, 0
             {{end}}
{{end}}

{{range $i, $fn := .Functions}}             case {{add 133 $i}}: // {{.Name}}
                {{if .Timeout}}
                ctx, cancel := context.WithTimeout(context.Background(), timeout_{{.Name}})
                {{else}}
                ctx := context.Background()
                cancel := func() {}
                {{end}}

                {{if .Async}}
                reqCopy := make([]byte, len(data))
                copy(reqCopy, data)
                select {
                case jobQueue <- func() {
                    defer cancel()
                    handle{{.Name}}(ctx, reqCopy, nil, handler, nil, client, mType, refCache, &refCacheMutex)
                }:
                default:
                    log.Error("Async worker pool full, dropping request", "func", "{{.Name}}")
                }

                builder.Reset()
                ipc.AckStart(builder)
                ipc.AckAddOk(builder, true)
                root := ipc.AckEnd(builder)
                builder.Finish(root)

                payload := builder.FinishedBytes()
                if cap(builder.Bytes) == cap(respBuf) && len(payload) <= len(respBuf) {
                    return -int32(len(payload)), server.MsgAck
                }
                if len(payload) > len(respBuf) { return 0, 0 }
                copy(respBuf, payload)
                return int32(len(payload)), server.MsgAck
                {{else}}
                defer cancel()
                len, respId := handle{{.Name}}(ctx, data, respBuf, handler, builder, client, mType, refCache, &refCacheMutex)
                return len, respId
                {{end}}
{{end}}
             default:
                return 0, 0
             }
	}

	client.Handle(dispatch)

	client.Start()
	client.Wait()
}

// ... handle functions ...
{{range $i, $fn := .Functions}}
func handle{{.Name}}(ctx context.Context, req []byte, respBuf []byte, handler XllService, b *flatbuffers.Builder, client *shm.Client, msgType shm.MsgType, refCache map[string][]byte, refCacheMutex *sync.RWMutex) (int32, shm.MsgType) {
	request := ipc.GetRootAs{{.Name}}Request(req, 0)
	_ = request

	// Extract args
	{{range .Args}}
	{{if eq .Type "string"}}
	arg_{{.Name}} := string(request.{{.Name|capitalize}}())
	{{else if eq .Type "int?"}}
	var arg_{{.Name}} *int32
	if v := request.{{.Name|capitalize}}(nil); v != nil {
		val := v.Val()
		arg_{{.Name}} = &val
	}
	{{else if eq .Type "float?"}}
	var arg_{{.Name}} *float64
	if v := request.{{.Name|capitalize}}(nil); v != nil {
		val := v.Val()
		arg_{{.Name}} = &val
	}
	{{else if eq .Type "bool?"}}
	var arg_{{.Name}} *bool
	if v := request.{{.Name|capitalize}}(nil); v != nil {
		val := v.Val()
		arg_{{.Name}} = &val
	}
	{{else if eq .Type "range"}}
	arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
	{{else if eq .Type "grid"}}
	arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
	{{else if eq .Type "numgrid"}}
	arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
	{{else if eq .Type "numgrid"}}
	arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
	{{else if eq .Type "any"}}
	var arg_{{.Name}} *types.Any
	arg_{{.Name}}_raw := request.{{.Name|capitalize}}(nil)
	if arg_{{.Name}}_raw != nil {
		if arg_{{.Name}}_raw.ValType() == types.AnyValueRefCache {
			var rc types.RefCache
			init := new(flatbuffers.Table)
			if arg_{{.Name}}_raw.Val(init) {
				rc.Init(init.Bytes, init.Pos)
				key := string(rc.Key())
				refCacheMutex.RLock()
				if data, ok := refCache[key]; ok {
					cacheReq := ipc.GetRootAsSetRefCacheRequest(data, 0)
					arg_{{.Name}} = cacheReq.Val(nil)
				} else {
					arg_{{.Name}} = arg_{{.Name}}_raw
				}
				refCacheMutex.RUnlock()
			}
		} else {
			arg_{{.Name}} = arg_{{.Name}}_raw
		}
	}
	{{else}}
	arg_{{.Name}} := request.{{.Name|capitalize}}()
	{{end}}
	{{end}}

	{{if .Caller}}
	caller := request.Caller(nil)
	{{end}}

	{{if .Async}}
	// Async execution
	handle := request.AsyncHandle()

	if ctx.Err() != nil {
		queueAsyncResult(handle, nil, server.AnyValueNone, ctx.Err().Error())
		return 0, 0
	}

	// Call handler with panic recovery
	func() {
		defer func() {
			if r := recover(); r != nil {
				stack := debug.Stack()
				log.Error("Panic in async handler {{.Name}}", "error", r, "stack", string(stack))
				queueAsyncResult(handle, nil, server.AnyValueNone, fmt.Sprintf("panic: %v", r))
			}
		}()

		res, err := handler.{{.Name}}(ctx{{range .Args}}, arg_{{.Name}}{{end}}{{if .Caller}}, caller{{end}})

		if err != nil {
			queueAsyncResult(handle, nil, server.AnyValueNone, err.Error())
		} else {
			{{if eq .Return "string"}}
			queueAsyncResult(handle, res, server.AnyValueStr, "")
			{{else if eq .Return "int"}}
			queueAsyncResult(handle, res, server.AnyValueInt, "")
			{{else if eq .Return "int?"}}
			if res != nil {
				queueAsyncResult(handle, *res, server.AnyValueInt, "")
			} else {
				queueAsyncResult(handle, nil, server.AnyValueNil, "")
			}
			{{else if eq .Return "float"}}
			queueAsyncResult(handle, res, server.AnyValueNum, "")
			{{else if eq .Return "float?"}}
			if res != nil {
				queueAsyncResult(handle, *res, server.AnyValueNum, "")
			} else {
				queueAsyncResult(handle, nil, server.AnyValueNil, "")
			}
			{{else if eq .Return "bool"}}
			queueAsyncResult(handle, res, server.AnyValueBool, "")
			{{else if eq .Return "bool?"}}
			if res != nil {
				queueAsyncResult(handle, *res, server.AnyValueBool, "")
			} else {
				queueAsyncResult(handle, nil, server.AnyValueNil, "")
			}
			{{end}}
		}
	}()

	return 0, 0
	{{else}}
	// Sync execution
	var res {{lookupGoType .Return}}
	var err error

	// Call handler with panic recovery
	func() {
		defer func() {
			if r := recover(); r != nil {
				stack := debug.Stack()
				log.Error("Panic in sync handler {{.Name}}", "error", r, "stack", string(stack))
				err = fmt.Errorf("panic: %v", r)
			}
		}()
		res, err = handler.{{.Name}}(ctx{{range .Args}}, arg_{{.Name}}{{end}}{{if .Caller}}, caller{{end}})
	}()

	b.Reset()
	var errOffset flatbuffers.UOffsetT
	if err != nil {
		errOffset = b.CreateString(err.Error())
	}

	{{if eq .Return "string"}}
	var resOffset flatbuffers.UOffsetT
	if err == nil {
		resOffset = b.CreateString(res)
	}
	{{else if eq .Return "int?"}}
	var resOffset flatbuffers.UOffsetT
	if err == nil && res != nil {
		types.IntStart(b)
		types.IntAddVal(b, *res)
		resOffset = types.IntEnd(b)
	}
	{{else if eq .Return "float?"}}
	var resOffset flatbuffers.UOffsetT
	if err == nil && res != nil {
		types.NumStart(b)
		types.NumAddVal(b, *res)
		resOffset = types.NumEnd(b)
	}
	{{else if eq .Return "bool?"}}
	var resOffset flatbuffers.UOffsetT
	if err == nil && res != nil {
		types.BoolStart(b)
		types.BoolAddVal(b, *res)
		resOffset = types.BoolEnd(b)
	}
	{{end}}

	ipc.{{.Name}}ResponseStart(b)
	if err != nil {
		ipc.{{.Name}}ResponseAddError(b, errOffset)
	} else {
		{{if or (eq .Return "string") (eq .Return "int?") (eq .Return "float?") (eq .Return "bool?")}}
		if resOffset > 0 {
			ipc.{{.Name}}ResponseAddResult(b, resOffset)
		}
		{{else}}
		ipc.{{.Name}}ResponseAddResult(b, res)
		{{end}}
	}
	root := ipc.{{.Name}}ResponseEnd(b)
	b.Finish(root)

	// Zero-Copy Return (Negative Size)
	// cap(b.Bytes) == cap(respBuf) implies it is still the SHM buffer.
	// If so, data is end-aligned and we return negative size.
	payload := b.FinishedBytes()
	if cap(b.Bytes) == cap(respBuf) && len(payload) <= len(respBuf) {
		return -int32(len(payload)), msgType
	}

	if len(payload) > len(respBuf) {
		// Chunking needed
		transferId := uint64(rand.Int63())

        out := &server.OutgoingChunk{
            Data:       make([]byte, len(payload)),
            Id:         transferId,
            MsgType:    uint32(msgType),
            LastAccess: time.Now(),
        }
		copy(out.Data, payload)
        chunkManager.AddOutgoingChunk(transferId, out)

		const chunkSize = 950 * 1024
		currentSize := chunkSize
		if len(out.Data) < chunkSize {
			currentSize = len(out.Data)
		}

		b.Reset()
		dataOff := b.CreateByteVector(out.Data[0:currentSize])
		ipc.ChunkStart(b)
		ipc.ChunkAddId(b, transferId)
		ipc.ChunkAddTotalSize(b, uint32(len(out.Data)))
		ipc.ChunkAddOffset(b, 0)
		ipc.ChunkAddData(b, dataOff)
		ipc.ChunkAddMsgType(b, uint32(msgType))
		root := ipc.ChunkEnd(b)
		b.FinishWithFileIdentifier(root, []byte("XCHN"))

		out.Offset = currentSize

		payload = b.FinishedBytes()
		if len(payload) > len(respBuf) {
			return 0, 0 // Fatal: Chunk header overhead made it > 1MB?
		}
		copy(respBuf, payload)
		return int32(len(payload)), server.MsgChunk
	}
	copy(respBuf, payload)
	return int32(len(payload)), msgType
	{{end}}
}

{{if .Async}}
func queueAsyncResult(handle uint64, val interface{}, valType server.AnyValue, errStr string) {
	asyncBatcher.QueueResult(handle, val, valType, errStr)
}
{{end}}
{{end}}

func flushCommands(b *flatbuffers.Builder) []byte {
    flushBuffers()
	cmdQueueLock.Lock()
	defer cmdQueueLock.Unlock()

	if len(cmdQueue) == 0 {
		return nil
	}

	wrappers := make([]flatbuffers.UOffsetT, len(cmdQueue))

	for i, c := range cmdQueue {
		var uOff flatbuffers.UOffsetT
		var uType ipc.Command

		if c.Data == nil {
			// Optimized Path
			sOff := b.CreateString(c.Sheet)

			types.RangeStartRefsVector(b, len(c.Rects))
			for j := len(c.Rects) - 1; j >= 0; j-- {
				types.CreateRect(b, c.Rects[j].RowFirst, c.Rects[j].RowLast, c.Rects[j].ColFirst, c.Rects[j].ColLast)
			}
			refsOff := b.EndVector(len(c.Rects))

			types.RangeStart(b)
			types.RangeAddSheetName(b, sOff)
			types.RangeAddRefs(b, refsOff)
			rOff := types.RangeEnd(b)

			if c.CmdType == 0 { // Set
				vOff := createScalarAny(b, c.ScalarVal)
				ipc.SetCommandStart(b)
				ipc.SetCommandAddTarget(b, rOff)
				ipc.SetCommandAddValue(b, vOff)
				uOff = ipc.SetCommandEnd(b)
				uType = ipc.CommandSetCommand
			} else { // Format
				fOff := b.CreateString(c.FormatStr)
				ipc.FormatCommandStart(b)
				ipc.FormatCommandAddTarget(b, rOff)
				ipc.FormatCommandAddFormat(b, fOff)
				uOff = ipc.FormatCommandEnd(b)
				uType = ipc.CommandFormatCommand
			}
		} else {
			// Legacy / Complex Path
			if c.CmdType == 0 {
				cmd := ipc.GetRootAsSetCommand(c.Data, 0)
				rOff := cloneRange(b, cmd.Target(nil))
				vOff := cloneAny(b, cmd.Value(nil))

				ipc.SetCommandStart(b)
				ipc.SetCommandAddTarget(b, rOff)
				ipc.SetCommandAddValue(b, vOff)
				uOff = ipc.SetCommandEnd(b)
				uType = ipc.CommandSetCommand
			} else {
				cmd := ipc.GetRootAsFormatCommand(c.Data, 0)
				rOff := cloneRange(b, cmd.Target(nil))
				fOff := b.CreateString(string(cmd.Format()))

				ipc.FormatCommandStart(b)
				ipc.FormatCommandAddTarget(b, rOff)
				ipc.FormatCommandAddFormat(b, fOff)
				uOff = ipc.FormatCommandEnd(b)
				uType = ipc.CommandFormatCommand
			}
		}

		ipc.CommandWrapperStart(b)
		ipc.CommandWrapperAddCmdType(b, uType)
		ipc.CommandWrapperAddCmd(b, uOff)
		wrappers[i] = ipc.CommandWrapperEnd(b)
	}

	ipc.CalculationEndedResponseStartCommandsVector(b, len(wrappers))
	for i := len(wrappers) - 1; i >= 0; i-- {
		b.PrependUOffsetT(wrappers[i])
	}
	cmdsOff := b.EndVector(len(wrappers))

	ipc.CalculationEndedResponseStart(b)
	ipc.CalculationEndedResponseAddCommands(b, cmdsOff)
	root := ipc.CalculationEndedResponseEnd(b)
	b.Finish(root)

	cmdQueue = nil
	return b.FinishedBytes()
}

func cloneRange(b *flatbuffers.Builder, r *types.Range) flatbuffers.UOffsetT {
	if r == nil { return 0 }
	s := r.SheetName()
	sOff := b.CreateString(string(s))

	l := r.RefsLength()
	types.RangeStartRefsVector(b, l)
	for i := l - 1; i >= 0; i-- {
		obj := new(types.Rect)
		if r.Refs(obj, i) {
			types.CreateRect(b, obj.RowFirst(), obj.RowLast(), obj.ColFirst(), obj.ColLast())
		}
	}
	refsOff := b.EndVector(l)

	types.RangeStart(b)
	types.RangeAddSheetName(b, sOff)
	types.RangeAddRefs(b, refsOff)
	return types.RangeEnd(b)
}

func cloneAny(b *flatbuffers.Builder, a *types.Any) flatbuffers.UOffsetT {
	if a == nil { return 0 }
	var uOff flatbuffers.UOffsetT
	t := a.ValType()

	var tbl flatbuffers.Table
	if a.Val(&tbl) {
		switch t {
		case types.AnyValueNum:
			var val types.Num
			val.Init(tbl.Bytes, tbl.Pos)
			types.NumStart(b)
			types.NumAddVal(b, val.Val())
			uOff = types.NumEnd(b)
		case types.AnyValueInt:
			var val types.Int
			val.Init(tbl.Bytes, tbl.Pos)
			types.IntStart(b)
			types.IntAddVal(b, val.Val())
			uOff = types.IntEnd(b)
		case types.AnyValueBool:
			var val types.Bool
			val.Init(tbl.Bytes, tbl.Pos)
			types.BoolStart(b)
			types.BoolAddVal(b, val.Val())
			uOff = types.BoolEnd(b)
		case types.AnyValueStr:
			var val types.Str
			val.Init(tbl.Bytes, tbl.Pos)
			sOff := b.CreateString(string(val.Val()))
			types.StrStart(b)
			types.StrAddVal(b, sOff)
			uOff = types.StrEnd(b)
		case types.AnyValueErr:
			var val types.Err
			val.Init(tbl.Bytes, tbl.Pos)
			types.ErrStart(b)
			types.ErrAddVal(b, val.Val())
			uOff = types.ErrEnd(b)
		case types.AnyValueNumGrid:
			var val types.NumGrid
			val.Init(tbl.Bytes, tbl.Pos)
			l := val.DataLength()
			types.NumGridStartDataVector(b, l)
			for i := l - 1; i >= 0; i-- {
				b.PrependFloat64(val.Data(i))
			}
			dataOff := b.EndVector(l)

			types.NumGridStart(b)
			types.NumGridAddRows(b, val.Rows())
			types.NumGridAddCols(b, val.Cols())
			types.NumGridAddData(b, dataOff)
			uOff = types.NumGridEnd(b)
		case types.AnyValueGrid:
			var val types.Grid
			val.Init(tbl.Bytes, tbl.Pos)
			uOff = cloneGrid(b, &val)
		case types.AnyValueRange:
			var val types.Range
			val.Init(tbl.Bytes, tbl.Pos)
			uOff = cloneRange(b, &val)
		case types.AnyValueRefCache:
			var val types.RefCache
			val.Init(tbl.Bytes, tbl.Pos)
			kOff := b.CreateString(string(val.Key()))
			types.RefCacheStart(b)
			types.RefCacheAddKey(b, kOff)
			uOff = types.RefCacheEnd(b)
		case types.AnyValueAsyncHandle:
			var val types.AsyncHandle
			val.Init(tbl.Bytes, tbl.Pos)
			types.AsyncHandleStart(b)
			types.AsyncHandleAddVal(b, val.Val())
			uOff = types.AsyncHandleEnd(b)
		default:
			// Nil
			types.NilStart(b)
			uOff = types.NilEnd(b)
		}
	} else {
		types.NilStart(b)
		uOff = types.NilEnd(b)
	}

	types.AnyStart(b)
	types.AnyAddValType(b, t)
	types.AnyAddVal(b, uOff)
	return types.AnyEnd(b)
}

func cloneGrid(b *flatbuffers.Builder, g *types.Grid) flatbuffers.UOffsetT {
	if g == nil {
		return 0
	}
	l := g.DataLength()
	offsets := make([]flatbuffers.UOffsetT, l)
	for i := 0; i < l; i++ {
		var s types.Scalar
		if g.Data(&s, i) {
			offsets[i] = cloneScalar(b, &s)
		}
	}

	types.GridStartDataVector(b, l)
	for i := l - 1; i >= 0; i-- {
		b.PrependUOffsetT(offsets[i])
	}
	dataOff := b.EndVector(l)

	types.GridStart(b)
	types.GridAddRows(b, g.Rows())
	types.GridAddCols(b, g.Cols())
	types.GridAddData(b, dataOff)
	return types.GridEnd(b)
}

func cloneScalar(b *flatbuffers.Builder, s *types.Scalar) flatbuffers.UOffsetT {
	if s == nil {
		return 0
	}

	var uOff flatbuffers.UOffsetT
	t := s.ValType()

	var tbl flatbuffers.Table
	if s.Val(&tbl) {
		switch t {
		case types.ScalarValueInt:
			var val types.Int
			val.Init(tbl.Bytes, tbl.Pos)
			types.IntStart(b)
			types.IntAddVal(b, val.Val())
			uOff = types.IntEnd(b)
		case types.ScalarValueNum:
			var val types.Num
			val.Init(tbl.Bytes, tbl.Pos)
			types.NumStart(b)
			types.NumAddVal(b, val.Val())
			uOff = types.NumEnd(b)
		case types.ScalarValueBool:
			var val types.Bool
			val.Init(tbl.Bytes, tbl.Pos)
			types.BoolStart(b)
			types.BoolAddVal(b, val.Val())
			uOff = types.BoolEnd(b)
		case types.ScalarValueStr:
			var val types.Str
			val.Init(tbl.Bytes, tbl.Pos)
			sOff := b.CreateString(string(val.Val()))
			types.StrStart(b)
			types.StrAddVal(b, sOff)
			uOff = types.StrEnd(b)
		case types.ScalarValueErr:
			var val types.Err
			val.Init(tbl.Bytes, tbl.Pos)
			types.ErrStart(b)
			types.ErrAddVal(b, val.Val())
			uOff = types.ErrEnd(b)
		case types.ScalarValueAsyncHandle:
			var val types.AsyncHandle
			val.Init(tbl.Bytes, tbl.Pos)
			types.AsyncHandleStart(b)
			types.AsyncHandleAddVal(b, val.Val())
			uOff = types.AsyncHandleEnd(b)
		default:
			types.NilStart(b)
			uOff = types.NilEnd(b)
		}
	} else {
		types.NilStart(b)
		uOff = types.NilEnd(b)
	}

	types.ScalarStart(b)
	types.ScalarAddValType(b, t)
	types.ScalarAddVal(b, uOff)
	return types.ScalarEnd(b)
}
