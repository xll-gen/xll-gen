// Code generated by xll-gen {{.Version}}. DO NOT EDIT.
package {{.Package}}

import (
	"context"
	"fmt"
	"math/rand"
	"os"
	"strings"
	"sync"
	"time"
	"runtime"
	"sort"
	"{{.ModName}}/generated/ipc"
	"{{.ModName}}/generated/ipc/types"
	"github.com/xll-gen/shm/go"
	flatbuffers "github.com/google/flatbuffers/go"
)

// Force usage of time and ipc/types to avoid unused import error
var _ = time.Now
var _ = types.Bool{}

const (
	MSG_ACK                  = 2
	MSG_CHUNK                = 128
	MSG_SETREFCACHE          = 129
	MSG_CALCULATION_ENDED    = 130
	MSG_CALCULATION_CANCELED = 131
	MSG_USER_START           = 132
)

type chunkBuffer struct {
	data       []byte
	totalSize  int
	received   int
	mutex      sync.Mutex
	lastAccess time.Time
}

type outgoingChunk struct {
	data       []byte
	offset     int
	id         uint64
	msgType    uint32
	lastAccess time.Time
}

// Command Queue
type queuedCommand struct {
	cmdType int // 0: Set, 1: Format
	data    []byte
}
var (
	cmdQueueLock sync.Mutex
	cmdQueue     []queuedCommand
)

// Optimization Structures
type Cell struct {
	Row int32
	Col int32
}

type mergedRect struct {
	r1, r2, c1, c2 int32
}

type ScalarValue struct {
	Type types.AnyValue
	Num  float64
	Int  int32
	Bool bool
	Str  string
	Err  int16
}

var (
	bufferedSets      = make(map[string]map[Cell]ScalarValue)
	bufferedFormats   = make(map[string]map[Cell]string)
	bufferLock        sync.Mutex
)

func ScheduleSet(r *types.Range, v *types.Any) {
	scalar, ok := toScalar(v)
	if ok {
		sheet := string(r.SheetName())
		bufferLock.Lock()
		if bufferedSets[sheet] == nil {
			bufferedSets[sheet] = make(map[Cell]ScalarValue)
		}

		l := r.RefsLength()
		for i := 0; i < l; i++ {
			var rect types.Rect
			if r.Refs(&rect, i) {
				for row := rect.RowFirst(); row <= rect.RowLast(); row++ {
					for col := rect.ColFirst(); col <= rect.ColLast(); col++ {
						bufferedSets[sheet][Cell{row, col}] = scalar
					}
				}
			}
		}
		bufferLock.Unlock()
		return
	}

	flushBuffers()

	b := flatbuffers.NewBuilder(0)
	rOff := cloneRange(b, r)
	vOff := cloneAny(b, v)

	ipc.SetCommandStart(b)
	ipc.SetCommandAddTarget(b, rOff)
	ipc.SetCommandAddValue(b, vOff)
	root := ipc.SetCommandEnd(b)
	b.Finish(root)

	cmdQueueLock.Lock()
	cmdQueue = append(cmdQueue, queuedCommand{0, b.FinishedBytes()})
	cmdQueueLock.Unlock()
}

func ScheduleFormat(r *types.Range, fmtStr string) {
	sheet := string(r.SheetName())
	bufferLock.Lock()
	if bufferedFormats[sheet] == nil {
		bufferedFormats[sheet] = make(map[Cell]string)
	}

	l := r.RefsLength()
	for i := 0; i < l; i++ {
		var rect types.Rect
		if r.Refs(&rect, i) {
			for row := rect.RowFirst(); row <= rect.RowLast(); row++ {
				for col := rect.ColFirst(); col <= rect.ColLast(); col++ {
					bufferedFormats[sheet][Cell{row, col}] = fmtStr
				}
			}
		}
	}
	bufferLock.Unlock()
}

func flushBuffers() {
	bufferLock.Lock()
	defer bufferLock.Unlock()

	// Process Sets
	for sheet, cells := range bufferedSets {
		byVal := make(map[ScalarValue][]Cell)
		for cell, val := range cells {
			byVal[val] = append(byVal[val], cell)
		}

		for val, cellList := range byVal {
			rects := greedyMesh(cellList)

			// Chunk by 32
			for i := 0; i < len(rects); i += 32 {
				end := i + 32
				if end > len(rects) { end = len(rects) }
				batch := rects[i:end]

				b := flatbuffers.NewBuilder(0)
				sOff := b.CreateString(sheet)

				types.RangeStartRefsVector(b, len(batch))
				for j := len(batch) - 1; j >= 0; j-- {
					types.CreateRect(b, batch[j].r1, batch[j].r2, batch[j].c1, batch[j].c2)
				}
				refsOff := b.EndVector(len(batch))

				types.RangeStart(b)
				types.RangeAddSheetName(b, sOff)
				types.RangeAddRefs(b, refsOff)
				rOff := types.RangeEnd(b)

				vOff := createScalarAny(b, val)

				ipc.SetCommandStart(b)
				ipc.SetCommandAddTarget(b, rOff)
				ipc.SetCommandAddValue(b, vOff)
				uOff := ipc.SetCommandEnd(b)
				b.Finish(uOff)

				cmdQueueLock.Lock()
				cmdQueue = append(cmdQueue, queuedCommand{0, b.FinishedBytes()})
				cmdQueueLock.Unlock()
			}
		}
		delete(bufferedSets, sheet)
	}

	// Process Formats
	for sheet, cells := range bufferedFormats {
		byFmt := make(map[string][]Cell)
		for cell, fmt := range cells {
			byFmt[fmt] = append(byFmt[fmt], cell)
		}

		for fmt, cellList := range byFmt {
			rects := greedyMesh(cellList)

			for i := 0; i < len(rects); i += 32 {
				end := i + 32
				if end > len(rects) { end = len(rects) }
				batch := rects[i:end]

				b := flatbuffers.NewBuilder(0)
				sOff := b.CreateString(sheet)

				types.RangeStartRefsVector(b, len(batch))
				for j := len(batch) - 1; j >= 0; j-- {
					types.CreateRect(b, batch[j].r1, batch[j].r2, batch[j].c1, batch[j].c2)
				}
				refsOff := b.EndVector(len(batch))

				types.RangeStart(b)
				types.RangeAddSheetName(b, sOff)
				types.RangeAddRefs(b, refsOff)
				rOff := types.RangeEnd(b)

				fOff := b.CreateString(fmt)

				ipc.FormatCommandStart(b)
				ipc.FormatCommandAddTarget(b, rOff)
				ipc.FormatCommandAddFormat(b, fOff)
				uOff := ipc.FormatCommandEnd(b)
				b.Finish(uOff)

				cmdQueueLock.Lock()
				cmdQueue = append(cmdQueue, queuedCommand{1, b.FinishedBytes()})
				cmdQueueLock.Unlock()
			}
		}
		delete(bufferedFormats, sheet)
	}
}

func greedyMesh(cells []Cell) []mergedRect {
	if len(cells) == 0 { return nil }

	sort.Slice(cells, func(i, j int) bool {
		if cells[i].Row != cells[j].Row {
			return cells[i].Row < cells[j].Row
		}
		return cells[i].Col < cells[j].Col
	})

	grid := make(map[Cell]bool, len(cells))
	for _, c := range cells {
		grid[c] = true
	}

	var rects []mergedRect
	visited := make(map[Cell]bool, len(cells))

	for _, c := range cells {
		if visited[c] { continue }

		rFirst, cFirst := c.Row, c.Col
		rLast, cLast := rFirst, cFirst

		// Expand Width
		for {
			nextCol := cLast + 1
			if grid[Cell{rFirst, nextCol}] && !visited[Cell{rFirst, nextCol}] {
				cLast = nextCol
			} else {
				break
			}
		}

		// Expand Height
		for {
			nextRow := rLast + 1
			canExpand := true
			for col := cFirst; col <= cLast; col++ {
				if !grid[Cell{nextRow, col}] || visited[Cell{nextRow, col}] {
					canExpand = false
					break
				}
			}
			if canExpand {
				rLast = nextRow
			} else {
				break
			}
		}

		for r := rFirst; r <= rLast; r++ {
			for c := cFirst; c <= cLast; c++ {
				visited[Cell{r, c}] = true
			}
		}

		rects = append(rects, mergedRect{rFirst, rLast, cFirst, cLast})
	}
	return rects
}

func toScalar(v *types.Any) (ScalarValue, bool) {
	if v == nil { return ScalarValue{}, false }
	var tbl flatbuffers.Table
	if !v.Val(&tbl) { return ScalarValue{}, false }

	switch v.ValType() {
	case types.AnyValueInt:
		var t types.Int; t.Init(tbl.Bytes, tbl.Pos)
		return ScalarValue{Type: types.AnyValueInt, Int: t.Val()}, true
	case types.AnyValueNum:
		var t types.Num; t.Init(tbl.Bytes, tbl.Pos)
		return ScalarValue{Type: types.AnyValueNum, Num: t.Val()}, true
	case types.AnyValueBool:
		var t types.Bool; t.Init(tbl.Bytes, tbl.Pos)
		return ScalarValue{Type: types.AnyValueBool, Bool: t.Val()}, true
	case types.AnyValueStr:
		var t types.Str; t.Init(tbl.Bytes, tbl.Pos)
		return ScalarValue{Type: types.AnyValueStr, Str: string(t.Val())}, true
	case types.AnyValueErr:
		var t types.Err; t.Init(tbl.Bytes, tbl.Pos)
		return ScalarValue{Type: types.AnyValueErr, Err: int16(t.Val())}, true
	}
	return ScalarValue{}, false
}

func createScalarAny(b *flatbuffers.Builder, val ScalarValue) flatbuffers.UOffsetT {
	var uOff flatbuffers.UOffsetT
	switch val.Type {
	case types.AnyValueInt:
		types.IntStart(b)
		types.IntAddVal(b, val.Int)
		uOff = types.IntEnd(b)
	case types.AnyValueNum:
		types.NumStart(b)
		types.NumAddVal(b, val.Num)
		uOff = types.NumEnd(b)
	case types.AnyValueBool:
		types.BoolStart(b)
		types.BoolAddVal(b, val.Bool)
		uOff = types.BoolEnd(b)
	case types.AnyValueStr:
		sOff := b.CreateString(val.Str)
		types.StrStart(b)
		types.StrAddVal(b, sOff)
		uOff = types.StrEnd(b)
	case types.AnyValueErr:
		types.ErrStart(b)
		types.ErrAddVal(b, types.XlError(val.Err))
		uOff = types.ErrEnd(b)
	}

	types.AnyStart(b)
	types.AnyAddValType(b, val.Type)
	types.AnyAddVal(b, uOff)
	return types.AnyEnd(b)
}

func Serve(handler XllService) {
	name := "{{.ProjectName}}"
	for _, arg := range os.Args {
		if strings.HasPrefix(arg, "-xll-shm=") {
			name = strings.TrimPrefix(arg, "-xll-shm=")
		}
	}

	client, err := shm.Connect(name)
	if err != nil {
		panic(fmt.Errorf("failed to connect to SHM: %w", err))
	}
	defer client.Close()

	// Global Ref Cache
	var refCacheMutex sync.RWMutex
	refCache := make(map[string][]byte)

	// Chunking Cache
	var chunkCacheMutex sync.Mutex
	chunkCache := make(map[uint64]*chunkBuffer)

	// Outgoing Chunks
	var outgoingChunksMutex sync.Mutex
	outgoingChunks := make(map[uint64]*outgoingChunk)

	// Cleanup Ticker
	go func() {
		ticker := time.NewTicker(30 * time.Second)
		for range ticker.C {
			now := time.Now()
			chunkCacheMutex.Lock()
			for id, buf := range chunkCache {
				if now.Sub(buf.lastAccess) > 60*time.Second {
					delete(chunkCache, id)
				}
			}
			chunkCacheMutex.Unlock()

			outgoingChunksMutex.Lock()
			for id, buf := range outgoingChunks {
				if now.Sub(buf.lastAccess) > 60*time.Second {
					delete(outgoingChunks, id)
				}
			}
			outgoingChunksMutex.Unlock()
		}
	}()

	// Configuration
	{{range .Functions}}
	{{if .Timeout}}
	timeout_{{.Name}}, _ := time.ParseDuration("{{.Timeout}}")
	{{end}}
	{{end}}

	workerCount := runtime.NumCPU()
	if n := {{.ServerWorkers}}; n > 0 {
		workerCount = n
	}

	// Worker Pool
	jobQueue := make(chan func(), workerCount)
	for i := 0; i < workerCount; i++ {
		go func() {
			for job := range jobQueue {
				job()
			}
		}()
	}

	client.Handle(func(req []byte, respBuf []byte, msgType shm.MsgType) (int32, shm.MsgType) {

        var dispatch func(data []byte, mType shm.MsgType) (int32, shm.MsgType)
        dispatch = func(data []byte, mType shm.MsgType) (int32, shm.MsgType) {
             builder := flatbuffers.NewBuilder(0)
             builder.Reset()

             switch uint32(mType) {
             case MSG_CALCULATION_ENDED:
                refCacheMutex.Lock()
                refCache = make(map[string][]byte)
                refCacheMutex.Unlock()

                {{if hasEvent "CalculationEnded" .Events}}
                var wg sync.WaitGroup
                wg.Add(1)
                jobQueue <- func() {
                    defer wg.Done()
                    if err := handler.OnCalculationEnded(context.Background()); err != nil {
                        fmt.Printf("Event handler OnCalculationEnded failed: %v\n", err)
                    }
                }
                wg.Wait()
                {{end}}

                respBytes := flushCommands()
                if len(respBytes) > 0 {
                    if len(respBytes) > len(respBuf) {
                        fmt.Printf("Warning: CalculationEnded response too large (%d)\n", len(respBytes))
                        return 0, 0
                    }
                    copy(respBuf, respBytes)
                    return int32(len(respBytes)), MSG_CALCULATION_ENDED
                }
                return 0, 0

             case MSG_CALCULATION_CANCELED:
                cmdQueueLock.Lock()
                cmdQueue = nil
                cmdQueueLock.Unlock()
                bufferLock.Lock()
                bufferedSets = make(map[string]map[Cell]ScalarValue)
                bufferedFormats = make(map[string]map[Cell]string)
                bufferLock.Unlock()

                {{if hasEvent "CalculationCanceled" .Events}}
                ctx := context.Background()
                jobQueue <- func() {
                    if err := handler.OnCalculationCanceled(ctx); err != nil {
                        fmt.Printf("Event handler OnCalculationCanceled failed: %v\n", err)
                    }
                }
                {{end}}
                return 0, 0

             case MSG_SETREFCACHE:
                reqObj := ipc.GetRootAsSetRefCacheRequest(data, 0)
                key := string(reqObj.Key())
                reqCopy := make([]byte, len(data))
                copy(reqCopy, data)

                refCacheMutex.Lock()
                refCache[key] = reqCopy
                refCacheMutex.Unlock()

                ipc.AckStart(builder)
                ipc.AckAddOk(builder, true)
                root := ipc.AckEnd(builder)
                builder.Finish(root)

                payload := builder.FinishedBytes()
                if len(payload) > len(respBuf) { return 0, 0 }
                copy(respBuf, payload)
                return int32(len(payload)), MSG_ACK

             case MSG_ACK:
                reqObj := ipc.GetRootAsAck(data, 0)
                id := reqObj.Id()
                outgoingChunksMutex.Lock()
                out, exists := outgoingChunks[id]
                if !exists {
                    outgoingChunksMutex.Unlock()
                    return 0, 0
                }
                out.lastAccess = time.Now()

                const chunkSize = 950 * 1024
                remaining := len(out.data) - out.offset
                currentSize := chunkSize
                if remaining < chunkSize { currentSize = remaining }

                if currentSize <= 0 {
                    delete(outgoingChunks, id)
                    outgoingChunksMutex.Unlock()
                    return 0, 0
                }

                builder.Reset()
                dataOff := builder.CreateByteVector(out.data[out.offset : out.offset+currentSize])
                ipc.ChunkStart(builder)
                ipc.ChunkAddId(builder, id)
                ipc.ChunkAddTotalSize(builder, uint32(len(out.data)))
                ipc.ChunkAddOffset(builder, uint32(out.offset))
                ipc.ChunkAddData(builder, dataOff)
                ipc.ChunkAddMsgType(builder, out.msgType)
                root := ipc.ChunkEnd(builder)
                builder.FinishWithFileIdentifier(root, []byte("XCHN"))

                out.offset += currentSize
                if out.offset >= len(out.data) { delete(outgoingChunks, id) }
                outgoingChunksMutex.Unlock()

                payload := builder.FinishedBytes()
                if len(payload) > len(respBuf) { return 0, 0 }
                copy(respBuf, payload)
                return int32(len(payload)), MSG_CHUNK

             case MSG_CHUNK:
                reqObj := ipc.GetRootAsChunk(data, 0)
                id := reqObj.Id()
                total := int(reqObj.TotalSize())
                offset := int(reqObj.Offset())
                dataLen := reqObj.DataLength()

                chunkCacheMutex.Lock()
                buf, exists := chunkCache[id]
                if !exists {
                    buf = &chunkBuffer{
                        data:       make([]byte, total),
                        totalSize:  total,
                        lastAccess: time.Now(),
                    }
                    chunkCache[id] = buf
                }
                buf.lastAccess = time.Now()
                chunkCacheMutex.Unlock()

                buf.mutex.Lock()
                if offset + dataLen <= len(buf.data) {
                    copy(buf.data[offset:], reqObj.DataBytes())
                    buf.received += dataLen
                }
                isComplete := buf.received >= buf.totalSize
                buf.mutex.Unlock()

                if isComplete {
                    chunkCacheMutex.Lock()
                    delete(chunkCache, id)
                    chunkCacheMutex.Unlock()

                    payloadMsgType := reqObj.MsgType()
                    return dispatch(buf.data, shm.MsgType(payloadMsgType))
                }

                ipc.AckStart(builder)
                ipc.AckAddId(builder, id)
                ipc.AckAddOk(builder, true)
                root := ipc.AckEnd(builder)
                builder.Finish(root)

                payload := builder.FinishedBytes()
                if len(payload) > len(respBuf) { return 0, 0 }
                copy(respBuf, payload)
                return int32(len(payload)), MSG_CHUNK

{{range .Events}}
             {{if and (ne .Type "CalculationEnded") (ne .Type "CalculationCanceled")}}
             case {{lookupEventId .Type}}:
                ctx := context.Background()
                jobQueue <- func() {
                    if err := handler.{{.Name}}(ctx); err != nil {
                        fmt.Printf("Event handler {{.Name}} failed: %v\n", err)
                    }
                }
                return 0, 0
             {{end}}
{{end}}

{{range $i, $fn := .Functions}}             case {{add 132 $i}}: // {{.Name}}
                {{if .Timeout}}
                ctx, cancel := context.WithTimeout(context.Background(), timeout_{{.Name}})
                {{else}}
                ctx := context.Background()
                cancel := func() {}
                {{end}}

                {{if .Async}}
                reqCopy := make([]byte, len(data))
                copy(reqCopy, data)
                jobQueue <- func() {
                    defer cancel()
                    handle{{.Name}}(ctx, reqCopy, nil, handler, nil, client, mType, refCache, &refCacheMutex, outgoingChunks, &outgoingChunksMutex)
                }
                return 0, 0
                {{else}}
                defer cancel()
                len, respId := handle{{.Name}}(ctx, data, respBuf, handler, builder, client, mType, refCache, &refCacheMutex, outgoingChunks, &outgoingChunksMutex)
                return len, respId
                {{end}}
{{end}}
             default:
                return 0, 0
             }
        }

        return dispatch(req, msgType)
	})

	client.Start()
	client.Wait()
}

// ... handle functions ...
{{range $i, $fn := .Functions}}
func handle{{.Name}}(ctx context.Context, req []byte, respBuf []byte, handler XllService, b *flatbuffers.Builder, client *shm.Client, msgType shm.MsgType, refCache map[string][]byte, refCacheMutex *sync.RWMutex, outgoingChunks map[uint64]*outgoingChunk, outgoingChunksMutex *sync.Mutex) (int32, shm.MsgType) {
	request := ipc.GetRootAs{{.Name}}Request(req, 0)
	_ = request

	// Extract args
	{{range .Args}}
	{{if eq .Type "string"}}
	arg_{{.Name}} := string(request.{{.Name|capitalize}}())
	{{else if eq .Type "int?"}}
	var arg_{{.Name}} *int32
	if v := request.{{.Name|capitalize}}(nil); v != nil {
		val := v.Val()
		arg_{{.Name}} = &val
	}
	{{else if eq .Type "float?"}}
	var arg_{{.Name}} *float64
	if v := request.{{.Name|capitalize}}(nil); v != nil {
		val := v.Val()
		arg_{{.Name}} = &val
	}
	{{else if eq .Type "bool?"}}
	var arg_{{.Name}} *bool
	if v := request.{{.Name|capitalize}}(nil); v != nil {
		val := v.Val()
		arg_{{.Name}} = &val
	}
	{{else if eq .Type "range"}}
	arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
	{{else if eq .Type "grid"}}
	arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
	{{else if eq .Type "numgrid"}}
	arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
	{{else if eq .Type "numgrid"}}
	arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
	{{else if eq .Type "any"}}
	var arg_{{.Name}} *types.Any
	arg_{{.Name}}_raw := request.{{.Name|capitalize}}(nil)
	if arg_{{.Name}}_raw != nil {
		if arg_{{.Name}}_raw.ValType() == types.AnyValueRefCache {
			var rc types.RefCache
			init := new(flatbuffers.Table)
			if arg_{{.Name}}_raw.Val(init) {
				rc.Init(init.Bytes, init.Pos)
				key := string(rc.Key())
				refCacheMutex.RLock()
				if data, ok := refCache[key]; ok {
					cacheReq := ipc.GetRootAsSetRefCacheRequest(data, 0)
					arg_{{.Name}} = cacheReq.Val(nil)
				}
				refCacheMutex.RUnlock()
			}
		} else {
			arg_{{.Name}} = arg_{{.Name}}_raw
		}
	}
	{{else}}
	arg_{{.Name}} := request.{{.Name|capitalize}}()
	{{end}}
	{{end}}

	{{if .Caller}}
	caller := request.Caller(nil)
	{{end}}

	{{if .Async}}
	// Async execution
	handle := request.AsyncHandle()

	if ctx.Err() != nil {
		sendAsyncError{{.Name}}(client, msgType, handle, ctx.Err())
		return 0, 0
	}

	// Call handler
	res, err := handler.{{.Name}}(ctx{{range .Args}}, arg_{{.Name}}{{end}}{{if .Caller}}, caller{{end}})

	b2 := flatbuffers.NewBuilder(0)
	var errOffset flatbuffers.UOffsetT
	if err != nil {
		errOffset = b2.CreateString(err.Error())
	}

	{{if eq .Return "string"}}
	var resOffset flatbuffers.UOffsetT
	if err == nil {
		resOffset = b2.CreateString(res)
	}
	{{else if eq .Return "int?"}}
	var resOffset flatbuffers.UOffsetT
	if err == nil && res != nil {
		types.IntStart(b2)
		types.IntAddVal(b2, *res)
		resOffset = types.IntEnd(b2)
	}
	{{else if eq .Return "float?"}}
	var resOffset flatbuffers.UOffsetT
	if err == nil && res != nil {
		types.NumStart(b2)
		types.NumAddVal(b2, *res)
		resOffset = types.NumEnd(b2)
	}
	{{else if eq .Return "bool?"}}
	var resOffset flatbuffers.UOffsetT
	if err == nil && res != nil {
		types.BoolStart(b2)
		types.BoolAddVal(b2, *res)
		resOffset = types.BoolEnd(b2)
	}
	{{end}}

	ipc.{{.Name}}ResponseStart(b2)
	ipc.{{.Name}}ResponseAddAsyncHandle(b2, handle)
	if err != nil {
		ipc.{{.Name}}ResponseAddError(b2, errOffset)
	} else {
		{{if or (eq .Return "string") (eq .Return "int?") (eq .Return "float?") (eq .Return "bool?")}}
		if resOffset > 0 {
			ipc.{{.Name}}ResponseAddResult(b2, resOffset)
		}
		{{else}}
		ipc.{{.Name}}ResponseAddResult(b2, res)
		{{end}}
	}
	root := ipc.{{.Name}}ResponseEnd(b2)
	b2.Finish(root)

	// Copy to respBuf
	payload := b.FinishedBytes()
	if len(payload) > len(respBuf) {
		// Chunking needed
		transferId := uint64(rand.Int63())

		outgoingChunksMutex.Lock()
		outgoingChunks[transferId] = &outgoingChunk{
			data:       make([]byte, len(payload)),
			id:         transferId,
			msgType:    uint32(msgType),
			lastAccess: time.Now(),
		}
		copy(outgoingChunks[transferId].data, payload)

		out := outgoingChunks[transferId]
		const chunkSize = 950 * 1024
		currentSize := chunkSize
		if len(out.data) < chunkSize {
			currentSize = len(out.data)
		}

		b.Reset()
		dataOff := b.CreateByteVector(out.data[0:currentSize])
		ipc.ChunkStart(b)
		ipc.ChunkAddId(b, transferId)
		ipc.ChunkAddTotalSize(b, uint32(len(out.data)))
		ipc.ChunkAddOffset(b, 0)
		ipc.ChunkAddData(b, dataOff)
		ipc.ChunkAddMsgType(b, uint32(msgType))
		root := ipc.ChunkEnd(b)
		b.FinishWithFileIdentifier(root, []byte("XCHN"))

		out.offset = currentSize
		outgoingChunksMutex.Unlock()

		payload = b.FinishedBytes()
		if len(payload) > len(respBuf) {
			return 0, 0 // Fatal: Chunk header overhead made it > 1MB?
		}
		copy(respBuf, payload)
		return int32(len(payload)), MSG_CHUNK
	}
	copy(respBuf, payload)
	return int32(len(payload)), msgType
	{{end}}
}

{{if .Async}}
func sendAsyncError{{.Name}}(client *shm.Client, msgType shm.MsgType, handle uint64, err error) {
	b := flatbuffers.NewBuilder(0)
	errOffset := b.CreateString(err.Error())
	ipc.{{.Name}}ResponseStart(b)
	ipc.{{.Name}}ResponseAddAsyncHandle(b, handle)
	ipc.{{.Name}}ResponseAddError(b, errOffset)
	root := ipc.{{.Name}}ResponseEnd(b)
	b.Finish(root)
	client.SendGuestCall(b.FinishedBytes(), msgType)
}
{{end}}
{{end}}

func flushCommands() []byte {
    flushBuffers()
	cmdQueueLock.Lock()
	defer cmdQueueLock.Unlock()

	if len(cmdQueue) == 0 {
		return nil
	}

	b := flatbuffers.NewBuilder(0)

	wrappers := make([]flatbuffers.UOffsetT, len(cmdQueue))

	for i, c := range cmdQueue {
		var uOff flatbuffers.UOffsetT
		var uType ipc.Command

		if c.cmdType == 0 {
			cmd := ipc.GetRootAsSetCommand(c.data, 0)
			rOff := cloneRange(b, cmd.Target(nil))
			vOff := cloneAny(b, cmd.Value(nil))

			ipc.SetCommandStart(b)
			ipc.SetCommandAddTarget(b, rOff)
			ipc.SetCommandAddValue(b, vOff)
			uOff = ipc.SetCommandEnd(b)
			uType = ipc.CommandSetCommand
		} else {
			cmd := ipc.GetRootAsFormatCommand(c.data, 0)
			rOff := cloneRange(b, cmd.Target(nil))
			fOff := b.CreateString(string(cmd.Format()))

			ipc.FormatCommandStart(b)
			ipc.FormatCommandAddTarget(b, rOff)
			ipc.FormatCommandAddFormat(b, fOff)
			uOff = ipc.FormatCommandEnd(b)
			uType = ipc.CommandFormatCommand
		}

		ipc.CommandWrapperStart(b)
		ipc.CommandWrapperAddCmdType(b, uType)
		ipc.CommandWrapperAddCmd(b, uOff)
		wrappers[i] = ipc.CommandWrapperEnd(b)
	}

	ipc.CalculationEndedResponseStartCommandsVector(b, len(wrappers))
	for i := len(wrappers) - 1; i >= 0; i-- {
		b.PrependUOffsetT(wrappers[i])
	}
	cmdsOff := b.EndVector(len(wrappers))

	ipc.CalculationEndedResponseStart(b)
	ipc.CalculationEndedResponseAddCommands(b, cmdsOff)
	root := ipc.CalculationEndedResponseEnd(b)
	b.Finish(root)

	cmdQueue = nil
	return b.FinishedBytes()
}

func cloneRange(b *flatbuffers.Builder, r *types.Range) flatbuffers.UOffsetT {
	if r == nil { return 0 }
	s := r.SheetName()
	sOff := b.CreateString(string(s))

	l := r.RefsLength()
	types.RangeStartRefsVector(b, l)
	for i := l - 1; i >= 0; i-- {
		obj := new(types.Rect)
		if r.Refs(obj, i) {
			types.CreateRect(b, obj.RowFirst(), obj.RowLast(), obj.ColFirst(), obj.ColLast())
		}
	}
	refsOff := b.EndVector(l)

	types.RangeStart(b)
	types.RangeAddSheetName(b, sOff)
	types.RangeAddRefs(b, refsOff)
	return types.RangeEnd(b)
}

func cloneAny(b *flatbuffers.Builder, a *types.Any) flatbuffers.UOffsetT {
	if a == nil { return 0 }
	var uOff flatbuffers.UOffsetT
	t := a.ValType()

    var tbl flatbuffers.Table
    if a.Val(&tbl) {
        switch t {
        case types.AnyValueNum:
            var val types.Num
            val.Init(tbl.Bytes, tbl.Pos)
            types.NumStart(b)
            types.NumAddVal(b, val.Num)
            uOff = types.NumEnd(b)
        case types.AnyValueInt:
            var val types.Int
            val.Init(tbl.Bytes, tbl.Pos)
            types.IntStart(b)
            types.IntAddVal(b, val.Val())
            uOff = types.IntEnd(b)
        case types.AnyValueBool:
            var val types.Bool
            val.Init(tbl.Bytes, tbl.Pos)
            types.BoolStart(b)
            types.BoolAddVal(b, val.Val())
            uOff = types.BoolEnd(b)
        case types.AnyValueStr:
            var val types.Str
            val.Init(tbl.Bytes, tbl.Pos)
            sOff := b.CreateString(string(val.Val()))
            types.StrStart(b)
            types.StrAddVal(b, sOff)
            uOff = types.StrEnd(b)
        case types.AnyValueErr:
            var val types.Err
            val.Init(tbl.Bytes, tbl.Pos)
            types.ErrStart(b)
            types.ErrAddVal(b, val.Val())
            uOff = types.ErrEnd(b)
        case types.AnyValueNumGrid:
            var val types.NumGrid
            val.Init(tbl.Bytes, tbl.Pos)
            l := val.DataLength()
            types.NumGridStartDataVector(b, l)
            for i := l - 1; i >= 0; i-- {
                b.PrependFloat64(val.Data(i))
            }
            dataOff := b.EndVector(l)

            types.NumGridStart(b)
            types.NumGridAddRows(b, val.Rows())
            types.NumGridAddCols(b, val.Cols())
            types.NumGridAddData(b, dataOff)
            uOff = types.NumGridEnd(b)
        // Missing: Grid, RefCache (simplified)
        default:
            // Nil
            types.NilStart(b)
            uOff = types.NilEnd(b)
        }
    } else {
        types.NilStart(b)
        uOff = types.NilEnd(b)
    }

	types.AnyStart(b)
	types.AnyAddValType(b, t)
	types.AnyAddVal(b, uOff)
	return types.AnyEnd(b)
}
