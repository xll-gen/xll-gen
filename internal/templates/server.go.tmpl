// Code generated by xll-gen {{.Version}}. DO NOT EDIT.
package {{.Package}}

import (
	"context"
	"fmt"
	"log/slog"
	"math/rand"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"
	"runtime"
	"runtime/debug"
	"{{.ModName}}/generated/ipc"
	"github.com/xll-gen/xll-gen/pkg/log"
	"github.com/xll-gen/xll-gen/pkg/server"
	"github.com/xll-gen/xll-gen/pkg/protocol"
	"github.com/xll-gen/shm/go"
	flatbuffers "github.com/google/flatbuffers/go"
)

// Force usage of time and protocol to avoid unused import error
var _ = time.Now
var _ = protocol.Bool{}

var (
	asyncBatcher   = server.NewAsyncBatcher()
	chunkManager   = server.NewChunkManager()
	commandBatcher = server.NewCommandBatcher()

	// Builder Pool to reduce GC pressure
	builderPool = sync.Pool{
		New: func() interface{} {
			return flatbuffers.NewBuilder(1024)
		},
	}

	// Heap Builder Pool for outgoing messages (retains buffer capacity)
	heapBuilderPool = sync.Pool{
		New: func() interface{} {
			return flatbuffers.NewBuilder(1024)
		},
	}
)

func ScheduleSet(r *protocol.Range, v *protocol.Any) {
	commandBatcher.ScheduleSet(r, v)
}

func ScheduleFormat(r *protocol.Range, fmtStr string) {
	commandBatcher.ScheduleFormat(r, fmtStr)
}

func Serve(handler XllService) {
	exePath, _ := os.Executable()
	binDir := filepath.Dir(exePath)

	logDir := "{{.Logging.Dir}}"
	logDir = strings.ReplaceAll(logDir, "${XLL_DIR}", os.Getenv("XLL_DIR"))
	logDir = strings.ReplaceAll(logDir, "${BIN_DIR}", binDir)

	if logDir == "" {
		logDir = "."
	}
	logPath := filepath.Join(logDir, "{{.ProjectName}}_go.log")

	if err := log.Init(logPath, "{{.Logging.Level}}"); err != nil {
		fmt.Printf("Failed to initialize logger: %v\n", err)
	}
	shm.SetLogger(slog.Default())

	name := "{{.ProjectName}}"
	for _, arg := range os.Args {
		if strings.HasPrefix(arg, "-xll-shm=") {
			name = strings.TrimPrefix(arg, "-xll-shm=")
		}
	}

	client, err := shm.Connect(shm.ClientConfig{ShmName: name})
	if err != nil {
		slog.Error("Failed to connect to SHM", "error", err)
		panic(fmt.Errorf("failed to connect to SHM: %w", err))
	}
	defer client.Close()

	var refCacheMutex sync.RWMutex
	refCache := make(map[string][]byte)

	asyncBatcher.StartWorker(func(batch []server.PendingAsyncResult) {
		server.FlushAsyncBatch(batch, client)
	})

	{{range .Functions}}
	{{if .Timeout}}
	timeout_{{.Name}}, _ := time.ParseDuration("{{.Timeout}}")
	{{end}}
	{{end}}

	workerCount := runtime.NumCPU()
	if n := {{.ServerWorkers}}; n > 0 {
		workerCount = n
	}

	jobQueue := make(chan func(), workerCount)
	for i := 0; i < workerCount; i++ {
		go func() {
			for job := range jobQueue {
				job()
			}
		}()
	}

	var dispatch func(data []byte, respBuf []byte, mType shm.MsgType) (int32, shm.MsgType)
	dispatch = func(data []byte, respBuf []byte, mType shm.MsgType) (int32, shm.MsgType) {
             builder := builderPool.Get().(*flatbuffers.Builder)
             if respBuf != nil && cap(respBuf) > 0 {
                 builder.Bytes = respBuf
             }
             builder.Reset()
             // Safety: Detach SHM buffer before returning to pool to prevent corruption
             defer func() {
                 builder.Bytes = nil
                 builderPool.Put(builder)
             }()

             switch uint32(mType) {
             case server.MsgCalculationEnded:
                refCacheMutex.Lock()
                refCache = make(map[string][]byte)
                refCacheMutex.Unlock()

                {{if hasEvent "CalculationEnded" .Events}}
                var wg sync.WaitGroup
                wg.Add(1)
                jobQueue <- func() {
                    defer wg.Done()
                    if err := handler.OnCalculationEnded(context.Background()); err != nil {
                        slog.Error("Event handler OnCalculationEnded failed", "error", err)
                    }
                }
                wg.Wait()
                {{end}}

                builder.Reset()
                respBytes := commandBatcher.FlushCommands(builder)
                if len(respBytes) > 0 {
                    // Zero-Copy Return (Negative Size)
                    if cap(builder.Bytes) == cap(respBuf) && len(respBytes) <= len(respBuf) {
                        return -int32(len(respBytes)), server.MsgCalculationEnded
                    }

                    if len(respBytes) > len(respBuf) {
                        slog.Warn("CalculationEnded response too large", "size", len(respBytes))
                        return 0, 0
                    }
                    copy(respBuf, respBytes)
                    return int32(len(respBytes)), server.MsgCalculationEnded
                }
                return 0, 0

             case server.MsgCalculationCanceled:
                commandBatcher.Clear()

                {{if hasEvent "CalculationCanceled" .Events}}
                ctx := context.Background()
                jobQueue <- func() {
                    if err := handler.OnCalculationCanceled(ctx); err != nil {
                        slog.Error("Event handler OnCalculationCanceled failed", "error", err)
                    }
                }
                {{end}}
                return 0, 0

             case server.MsgSetRefCache:
                reqObj := protocol.GetRootAsSetRefCacheRequest(data, 0)
                key := string(reqObj.Key())
                reqCopy := make([]byte, len(data))
                copy(reqCopy, data)

                refCacheMutex.Lock()
                refCache[key] = reqCopy
                refCacheMutex.Unlock()

                protocol.AckStart(builder)
                protocol.AckAddOk(builder, true)
                root := protocol.AckEnd(builder)
                builder.Finish(root)

                // Debug Log: ACK Prepared
                slog.Debug("ACK sent", "func", "SetRefCache")

                payload := builder.FinishedBytes()
                if cap(builder.Bytes) == cap(respBuf) && len(payload) <= len(respBuf) {
                    return -int32(len(payload)), server.MsgAck
                }
                if len(payload) > len(respBuf) { return 0, 0 }
                copy(respBuf, payload)
                return int32(len(payload)), server.MsgAck

             case server.MsgAck:
                reqObj := protocol.GetRootAsAck(data, 0)
                id := reqObj.Id()

                const chunkSize = 950 * 1024
                chunkData, msgType, totalSize, offset, found := chunkManager.GetNextChunk(id, chunkSize)

                if !found {
                    return 0, 0
                }

                if len(chunkData) == 0 {
                    return 0, 0
                }

                builder.Reset()
                dataOff := builder.CreateByteVector(chunkData)
                protocol.ChunkStart(builder)
                protocol.ChunkAddId(builder, id)
                protocol.ChunkAddTotalSize(builder, uint32(totalSize))
                protocol.ChunkAddOffset(builder, uint32(offset))
                protocol.ChunkAddData(builder, dataOff)
                protocol.ChunkAddMsgType(builder, msgType)
                root := protocol.ChunkEnd(builder)
                builder.FinishWithFileIdentifier(root, []byte("XCHN"))

                payload := builder.FinishedBytes()
                if cap(builder.Bytes) == cap(respBuf) && len(payload) <= len(respBuf) {
                    return -int32(len(payload)), server.MsgChunk
                }
                if len(payload) > len(respBuf) { return 0, 0 }
                copy(respBuf, payload)
                return int32(len(payload)), server.MsgChunk

             case server.MsgChunk:
                reqObj := protocol.GetRootAsChunk(data, 0)
                id := reqObj.Id()
                total := int(reqObj.TotalSize())
                offset := int(reqObj.Offset())
                dataLen := reqObj.DataLength()

                buf := chunkManager.GetChunkBuffer(id, total)

                buf.Mutex.Lock()
                if offset + dataLen <= len(buf.Data) {
                    copy(buf.Data[offset:], reqObj.DataBytes())
                    buf.Received += dataLen
                }
                isComplete := buf.Received >= buf.TotalSize
                buf.Mutex.Unlock()

                if isComplete {
                    chunkManager.RemoveChunkBuffer(id)
                    payloadMsgType := reqObj.MsgType()
                    return dispatch(buf.Data, respBuf, shm.MsgType(payloadMsgType))
                }

                protocol.AckStart(builder)
                protocol.AckAddId(builder, id)
                protocol.AckAddOk(builder, true)
                root := protocol.AckEnd(builder)
                builder.Finish(root)

                payload := builder.FinishedBytes()
                if cap(builder.Bytes) == cap(respBuf) && len(payload) <= len(respBuf) {
                    return -int32(len(payload)), server.MsgChunk
                }
                if len(payload) > len(respBuf) { return 0, 0 }
                copy(respBuf, payload)
                return int32(len(payload)), server.MsgChunk

{{range .Events}}
             {{if and (ne .Type "CalculationEnded") (ne .Type "CalculationCanceled")}}
             case {{lookupEventId .Type}}:
                ctx := context.Background()
                jobQueue <- func() {
                    if err := handler.{{.Name}}(ctx); err != nil {
                        slog.Error("Event handler {{.Name}} failed", "error", err)
                    }
                }
                return 0, 0
             {{end}}
{{end}}

{{range $i, $fn := .Functions}}             case {{add 133 $i}}: // {{.Name}}
                {{if .Timeout}}
                ctx, cancel := context.WithTimeout(context.Background(), timeout_{{.Name}})
                {{else}}
                ctx := context.Background()
                cancel := func() {}
                {{end}}

                {{if .Async}}
                reqCopy := make([]byte, len(data))
                copy(reqCopy, data)
                select {
                case jobQueue <- func() {
                    defer cancel()
                    handle{{.Name}}(ctx, reqCopy, nil, handler, nil, client, mType, refCache, &refCacheMutex)
                }:
                default:
                    slog.Error("Async worker pool full, dropping request", "func", "{{.Name}}")
                }

                builder.Reset()
                protocol.AckStart(builder)
                protocol.AckAddOk(builder, true)
                root := protocol.AckEnd(builder)
                builder.Finish(root)

                payload := builder.FinishedBytes()
                if cap(builder.Bytes) == cap(respBuf) && len(payload) <= len(respBuf) {
                    return -int32(len(payload)), server.MsgAck
                }
                if len(payload) > len(respBuf) { return 0, 0 }
                copy(respBuf, payload)
                return int32(len(payload)), server.MsgAck
                {{else}}
                defer cancel()
                len, respId := handle{{.Name}}(ctx, data, respBuf, handler, builder, client, mType, refCache, &refCacheMutex)
                return len, respId
                {{end}}
{{end}}
             default:
                return 0, 0
             }
	}

	client.Handle(dispatch)

	client.Start()
	client.Wait()
}

// ... handle functions ...
{{range $i, $fn := .Functions}}
func handle{{.Name}}(ctx context.Context, req []byte, respBuf []byte, handler XllService, b *flatbuffers.Builder, client *shm.Client, msgType shm.MsgType, refCache map[string][]byte, refCacheMutex *sync.RWMutex) (int32, shm.MsgType) {
	request := ipc.GetRootAs{{.Name}}Request(req, 0)
	_ = request

	{{range .Args}}
	{{if eq .Type "string"}}
	arg_{{.Name}} := string(request.{{.Name|capitalize}}())
	{{else if eq .Type "int?"}}
	var arg_{{.Name}} *int32
	if v := request.{{.Name|capitalize}}(nil); v != nil {
		val := v.Val()
		arg_{{.Name}} = &val
	}
	{{else if eq .Type "float?"}}
	var arg_{{.Name}} *float64
	if v := request.{{.Name|capitalize}}(nil); v != nil {
		val := v.Val()
		arg_{{.Name}} = &val
	}
	{{else if eq .Type "bool?"}}
	var arg_{{.Name}} *bool
	if v := request.{{.Name|capitalize}}(nil); v != nil {
		val := v.Val()
		arg_{{.Name}} = &val
	}
	{{else if eq .Type "range"}}
	arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
	{{else if eq .Type "grid"}}
	arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
	{{else if eq .Type "numgrid"}}
	arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
	{{else if eq .Type "numgrid"}}
	arg_{{.Name}} := request.{{.Name|capitalize}}(nil)
	{{else if eq .Type "any"}}
	var arg_{{.Name}} *protocol.Any
	arg_{{.Name}}_raw := request.{{.Name|capitalize}}(nil)
	if arg_{{.Name}}_raw != nil {
		if arg_{{.Name}}_raw.ValType() == protocol.AnyValueRefCache {
			var rc protocol.RefCache
			init := new(flatbuffers.Table)
			if arg_{{.Name}}_raw.Val(init) {
				rc.Init(init.Bytes, init.Pos)
				key := string(rc.Key())
				refCacheMutex.RLock()
				if data, ok := refCache[key]; ok {
					cacheReq := protocol.GetRootAsSetRefCacheRequest(data, 0)
					arg_{{.Name}} = cacheReq.Val(nil)
				} else {
					arg_{{.Name}} = arg_{{.Name}}_raw
				}
				refCacheMutex.RUnlock()
			}
		} else {
			arg_{{.Name}} = arg_{{.Name}}_raw
		}
	}
	{{else}}
	arg_{{.Name}} := request.{{.Name|capitalize}}()
	{{end}}
	{{end}}

	{{if .Caller}}
	caller := request.Caller(nil)
	{{end}}

	{{if .Async}}
	handle := request.AsyncHandle()

	// Debug Log: Function Start
	slog.Debug("Async function start", "func", "{{.Name}}", "reqID", handle)

	if ctx.Err() != nil {
		queueAsyncResult(handle, nil, protocol.AnyValue(0), ctx.Err().Error())
		return 0, 0
	}

	func() {
		defer func() {
			if r := recover(); r != nil {
				stack := debug.Stack()
				slog.Error("Panic in async handler {{.Name}}", "error", r, "stack", string(stack))
				queueAsyncResult(handle, nil, protocol.AnyValue(0), fmt.Sprintf("panic: %v", r))
			}
			// Debug Log: Function End
			slog.Debug("Async function end", "func", "{{.Name}}", "reqID", handle)
		}()

		// Debug Log: Ack Sent (Implicitly handled by return 0,0 below which sends ACK)
		// But we want to log it explicitly if requested.
		// The caller of handle{{.Name}} sends the ACK immediately after this returns 0,0.
		// So we can log "ACK Sent" here? No, the caller sends it.
		// Let's log "Processing" here.
		slog.Debug("Processing async request", "func", "{{.Name}}", "reqID", handle)

		res, err := handler.{{.Name}}(ctx{{range .Args}}, arg_{{.Name}}{{end}}{{if .Caller}}, caller{{end}})

		if err != nil {
			queueAsyncResult(handle, nil, protocol.AnyValue(0), err.Error())
		} else {
			{{if eq .Return "string"}}
			queueAsyncResult(handle, res, protocol.AnyValueStr, "")
			{{else if eq .Return "int"}}
			queueAsyncResult(handle, res, protocol.AnyValueInt, "")
			{{else if eq .Return "int?"}}
			if res != nil {
				queueAsyncResult(handle, *res, protocol.AnyValueInt, "")
			} else {
				queueAsyncResult(handle, nil, protocol.AnyValueNil, "")
			}
			{{else if eq .Return "float"}}
			queueAsyncResult(handle, res, protocol.AnyValueNum, "")
			{{else if eq .Return "float?"}}
			if res != nil {
				queueAsyncResult(handle, *res, protocol.AnyValueNum, "")
			} else {
				queueAsyncResult(handle, nil, protocol.AnyValueNil, "")
			}
			{{else if eq .Return "bool"}}
			queueAsyncResult(handle, res, protocol.AnyValueBool, "")
			{{else if eq .Return "bool?"}}
			if res != nil {
				queueAsyncResult(handle, *res, protocol.AnyValueBool, "")
			} else {
				queueAsyncResult(handle, nil, protocol.AnyValueNil, "")
			}
			{{end}}
		}
	}()

	return 0, 0
	{{else}}
	var res {{lookupGoType .Return}}
	var err error

	slog.Debug("Sync function start", "func", "{{.Name}}")

	func() {
		defer func() {
			if r := recover(); r != nil {
				stack := debug.Stack()
				slog.Error("Panic in sync handler {{.Name}}", "error", r, "stack", string(stack))
				err = fmt.Errorf("panic: %v", r)
			}
			slog.Debug("Sync function end", "func", "{{.Name}}")
		}()
		res, err = handler.{{.Name}}(ctx{{range .Args}}, arg_{{.Name}}{{end}}{{if .Caller}}, caller{{end}})
	}()

	b.Reset()
	var errOffset flatbuffers.UOffsetT
	if err != nil {
		errOffset = b.CreateString(err.Error())
	}

	{{if eq .Return "string"}}
	var resOffset flatbuffers.UOffsetT
	if err == nil {
		resOffset = b.CreateString(res)
	}
	{{else if eq .Return "int?"}}
	var resOffset flatbuffers.UOffsetT
	if err == nil && res != nil {
		protocol.IntStart(b)
		protocol.IntAddVal(b, *res)
		resOffset = protocol.IntEnd(b)
	}
	{{else if eq .Return "float?"}}
	var resOffset flatbuffers.UOffsetT
	if err == nil && res != nil {
		protocol.NumStart(b)
		protocol.NumAddVal(b, *res)
		resOffset = protocol.NumEnd(b)
	}
	{{else if eq .Return "bool?"}}
	var resOffset flatbuffers.UOffsetT
	if err == nil && res != nil {
		protocol.BoolStart(b)
		protocol.BoolAddVal(b, *res)
		resOffset = protocol.BoolEnd(b)
	}
	{{end}}

	ipc.{{.Name}}ResponseStart(b)
	if err != nil {
		ipc.{{.Name}}ResponseAddError(b, errOffset)
	} else {
		{{if or (eq .Return "string") (eq .Return "int?") (eq .Return "float?") (eq .Return "bool?")}}
		if resOffset > 0 {
			ipc.{{.Name}}ResponseAddResult(b, resOffset)
		}
		{{else}}
		ipc.{{.Name}}ResponseAddResult(b, res)
		{{end}}
	}
	root := ipc.{{.Name}}ResponseEnd(b)
	b.Finish(root)

	// Zero-Copy Return (Negative Size)
	// cap(b.Bytes) == cap(respBuf) implies it is still the SHM buffer.
	// If so, data is end-aligned and we return negative size.
	payload := b.FinishedBytes()
	if cap(b.Bytes) == cap(respBuf) && len(payload) <= len(respBuf) {
		return -int32(len(payload)), msgType
	}

	if len(payload) > len(respBuf) {
		// Chunking needed
		transferId := uint64(rand.Int63())

        out := &server.OutgoingChunk{
            Data:       make([]byte, len(payload)),
            Id:         transferId,
            MsgType:    uint32(msgType),
            LastAccess: time.Now(),
        }
		copy(out.Data, payload)
        chunkManager.AddOutgoingChunk(transferId, out)

		const chunkSize = 950 * 1024
		currentSize := chunkSize
		if len(out.Data) < chunkSize {
			currentSize = len(out.Data)
		}

		b.Reset()
		dataOff := b.CreateByteVector(out.Data[0:currentSize])
		protocol.ChunkStart(b)
		protocol.ChunkAddId(b, transferId)
		protocol.ChunkAddTotalSize(b, uint32(len(out.Data)))
		protocol.ChunkAddOffset(b, 0)
		protocol.ChunkAddData(b, dataOff)
		protocol.ChunkAddMsgType(b, uint32(msgType))
		root := protocol.ChunkEnd(b)
		b.FinishWithFileIdentifier(root, []byte("XCHN"))

		out.Offset = currentSize

		payload = b.FinishedBytes()
		if len(payload) > len(respBuf) {
			return 0, 0 // Fatal: Chunk header overhead made it > 1MB?
		}
		copy(respBuf, payload)
		return int32(len(payload)), server.MsgChunk
	}
	copy(respBuf, payload)
	return int32(len(payload)), msgType
	{{end}}
}

{{end}}

{{if hasAsync .Functions}}
func queueAsyncResult(handle uint64, val interface{}, valType protocol.AnyValue, errStr string) {
	asyncBatcher.QueueResult(handle, val, valType, errStr)
}
{{end}}
