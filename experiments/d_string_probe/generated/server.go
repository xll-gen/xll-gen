// Code generated by xll-gen v0.1.0. DO NOT EDIT.
package generated

import (
	"context"
	"fmt"
	"math/rand"
	"os"
	"strings"
	"sync"
	"time"
	"probe_experiment/generated/ipc"
	"probe_experiment/generated/ipc/types"
	"github.com/xll-gen/shm/go"
	flatbuffers "github.com/google/flatbuffers/go"
)

// Force usage of time and ipc/types to avoid unused import error
var _ = time.Now
var _ = types.Bool{}

const (
	MSG_ACK                  = 2
	MSG_CHUNK                = 128
	MSG_SETREFCACHE          = 129
	MSG_CALCULATION_ENDED    = 130
	MSG_CALCULATION_CANCELED = 131
	MSG_USER_START           = 132
)

type chunkBuffer struct {
	data       []byte
	totalSize  int
	received   int
	mutex      sync.Mutex
	lastAccess time.Time
}

type outgoingChunk struct {
	data       []byte
	offset     int
	id         uint64
	msgId      uint32
	lastAccess time.Time
}

func Serve(handler XllService) {
	name := "ProbeExperiment"
	for _, arg := range os.Args {
		if strings.HasPrefix(arg, "-xll-shm=") {
			name = strings.TrimPrefix(arg, "-xll-shm=")
		}
	}

	client, err := shm.Connect(name)
	if err != nil {
		panic(fmt.Errorf("failed to connect to SHM: %w", err))
	}
	defer client.Close()

	// Global Ref Cache
	var refCacheMutex sync.RWMutex
	refCache := make(map[string][]byte)

	// Chunking Cache
	var chunkCacheMutex sync.Mutex
	chunkCache := make(map[uint64]*chunkBuffer)

	// Outgoing Chunks
	var outgoingChunksMutex sync.Mutex
	outgoingChunks := make(map[uint64]*outgoingChunk)

	// Cleanup Ticker
	go func() {
		ticker := time.NewTicker(30 * time.Second)
		for range ticker.C {
			now := time.Now()
			chunkCacheMutex.Lock()
			for id, buf := range chunkCache {
				if now.Sub(buf.lastAccess) > 60*time.Second {
					delete(chunkCache, id)
				}
			}
			chunkCacheMutex.Unlock()

			outgoingChunksMutex.Lock()
			for id, buf := range outgoingChunks {
				if now.Sub(buf.lastAccess) > 60*time.Second {
					delete(outgoingChunks, id)
				}
			}
			outgoingChunksMutex.Unlock()
		}
	}()

	// Configuration




	workerCount := 100
	if n := 0; n > 0 {
		workerCount = n
	}

	// Worker Pool
	jobQueue := make(chan func(), workerCount)
	for i := 0; i < workerCount; i++ {
		go func() {
			for job := range jobQueue {
				job()
			}
		}()
	}

	client.Handle(func(req []byte, respBuf []byte, msgId uint32) (int32, shm.MsgType) {
		builder := flatbuffers.NewBuilder(0)
		builder.Reset()

		switch msgId {
		case MSG_CALCULATION_ENDED: // 130
			refCacheMutex.Lock()
			refCache = make(map[string][]byte)
			refCacheMutex.Unlock()

			return 0, 0

		case MSG_CALCULATION_CANCELED: // 131

			return 0, 0

		case MSG_SETREFCACHE: // 129
			reqObj := ipc.GetRootAsSetRefCacheRequest(req, 0)
			key := string(reqObj.Key())

			reqCopy := make([]byte, len(req))
			copy(reqCopy, req)

			refCacheMutex.Lock()
			refCache[key] = reqCopy
			refCacheMutex.Unlock()

			// Send Ack (MsgID 2)
			ipc.AckStart(builder)
			ipc.AckAddOk(builder, true)
			root := ipc.AckEnd(builder)
			builder.Finish(root)

			payload := builder.FinishedBytes()
			if len(payload) > len(respBuf) { return 0, 0 }
			copy(respBuf, payload)
			return int32(len(payload)), MSG_ACK

		case MSG_ACK: // 2 (Ack for outgoing chunk)
			reqObj := ipc.GetRootAsAck(req, 0)
			id := reqObj.Id()
			// ok := reqObj.Ok() // Assuming true means "give me next"

			outgoingChunksMutex.Lock()
			out, exists := outgoingChunks[id]
			if !exists {
				outgoingChunksMutex.Unlock()
				return 0, 0
			}
			out.lastAccess = time.Now()

			// Send next chunk
			const chunkSize = 950 * 1024
			remaining := len(out.data) - out.offset
			currentSize := chunkSize
			if remaining < chunkSize {
				currentSize = remaining
			}

			if currentSize <= 0 {
				// Done
				delete(outgoingChunks, id)
				outgoingChunksMutex.Unlock()
				return 0, 0
			}

			builder.Reset()
			dataOff := builder.CreateByteVector(out.data[out.offset : out.offset+currentSize])
			ipc.ChunkStart(builder)
			ipc.ChunkAddId(builder, id)
			ipc.ChunkAddTotalSize(builder, uint32(len(out.data)))
			ipc.ChunkAddOffset(builder, uint32(out.offset))
			ipc.ChunkAddData(builder, dataOff)
			ipc.ChunkAddMsgId(builder, out.msgId) // Original MsgID
			root := ipc.ChunkEnd(builder)
			builder.FinishWithFileIdentifier(root, []byte("XCHN"))

			out.offset += currentSize
			if out.offset >= len(out.data) {
				delete(outgoingChunks, id)
			}
			outgoingChunksMutex.Unlock()

			payload := builder.FinishedBytes()
			if len(payload) > len(respBuf) { return 0, 0 }
			copy(respBuf, payload)
			return int32(len(payload)), MSG_CHUNK

		case MSG_CHUNK: // 128 (Incoming Chunk)
			reqObj := ipc.GetRootAsChunk(req, 0)
			id := reqObj.Id()
			total := int(reqObj.TotalSize())
			offset := int(reqObj.Offset())
			dataLen := reqObj.DataLength()

			chunkCacheMutex.Lock()
			buf, exists := chunkCache[id]
			if !exists {
				buf = &chunkBuffer{
					data:       make([]byte, total),
					totalSize:  total,
					lastAccess: time.Now(),
				}
				chunkCache[id] = buf
			}
			buf.lastAccess = time.Now()
			chunkCacheMutex.Unlock()

			buf.mutex.Lock()
			if offset + dataLen <= len(buf.data) {
				copy(buf.data[offset:], reqObj.DataBytes())
				buf.received += dataLen
			}

			isComplete := buf.received >= buf.totalSize
			buf.mutex.Unlock()

			if isComplete {
				chunkCacheMutex.Lock()
				delete(chunkCache, id)
				chunkCacheMutex.Unlock()

				// Reassembled
				payloadMsgId := reqObj.MsgId()
				if payloadMsgId == MSG_SETREFCACHE { // 129
					cacheReq := ipc.GetRootAsSetRefCacheRequest(buf.data, 0)
					key := string(cacheReq.Key())

					refCacheMutex.Lock()
					refCache[key] = buf.data
					refCacheMutex.Unlock()

					// Final Ack
					ipc.AckStart(builder)
					ipc.AckAddOk(builder, true)
					root := ipc.AckEnd(builder)
					builder.Finish(root)

					payload := builder.FinishedBytes()
					if len(payload) > len(respBuf) { return 0, 0 }
					copy(respBuf, payload)
					return int32(len(payload)), MSG_ACK
				}
				// Handle other message types if needed
				return 0, 0
			}

			// Acknowledge this chunk to request next
			ipc.AckStart(builder)
			ipc.AckAddId(builder, id)
			ipc.AckAddOk(builder, true)
			root := ipc.AckEnd(builder)
			builder.Finish(root)

			payload := builder.FinishedBytes()
			if len(payload) > len(respBuf) { return 0, 0 }
			copy(respBuf, payload)
			return int32(len(payload)), MSG_ACK



		case 132: // ProbeString

			ctx := context.Background()
			cancel := func() {}



			// Sync: Run inline
			defer cancel()
			len, respId := handleProbeString(ctx, req, respBuf, handler, builder, client, msgId, refCache, &refCacheMutex, outgoingChunks, &outgoingChunksMutex)
			return len, respId

		default:
			return 0, 0
		}
	})

	client.Start()
	client.Wait()
}


func handleProbeString(ctx context.Context, req []byte, respBuf []byte, handler XllService, b *flatbuffers.Builder, client *shm.Client, msgId uint32, refCache map[string][]byte, refCacheMutex *sync.RWMutex, outgoingChunks map[uint64]*outgoingChunk, outgoingChunksMutex *sync.Mutex) (int32, shm.MsgType) {
	request := ipc.GetRootAsProbeStringRequest(req, 0)

	// Extract args


	arg_s := string(request.S())






	// Sync execution
	// Call handler
	res, err := handler.ProbeString(ctx, arg_s)

	b.Reset()
	var errOffset flatbuffers.UOffsetT
	if err != nil {
		errOffset = b.CreateString(err.Error())
	}


	var resOffset flatbuffers.UOffsetT
	if err == nil {
		resOffset = b2.CreateString(res)
	}


	ipc.ProbeStringResponseStart(b)
	if err != nil {
		ipc.ProbeStringResponseAddError(b, errOffset)
	} else {

		if resOffset > 0 {
			ipc.ProbeStringResponseAddResult(b, resOffset)
		}

	}
	root := ipc.ProbeStringResponseEnd(b)
	b.Finish(root)

	// Copy to respBuf
	payload := b.FinishedBytes()
	if len(payload) > len(respBuf) {
		// Chunking needed
		transferId := uint64(rand.Int63())

		outgoingChunksMutex.Lock()
		outgoingChunks[transferId] = &outgoingChunk{
			data:       make([]byte, len(payload)),
			id:         transferId,
			msgId:      msgId,
			lastAccess: time.Now(),
		}
		copy(outgoingChunks[transferId].data, payload)

		out := outgoingChunks[transferId]
		const chunkSize = 950 * 1024
		currentSize := chunkSize
		if len(out.data) < chunkSize {
			currentSize = len(out.data)
		}

		b.Reset()
		dataOff := b.CreateByteVector(out.data[0:currentSize])
		ipc.ChunkStart(b)
		ipc.ChunkAddId(b, transferId)
		ipc.ChunkAddTotalSize(b, uint32(len(out.data)))
		ipc.ChunkAddOffset(b, 0)
		ipc.ChunkAddData(b, dataOff)
		ipc.ChunkAddMsgId(b, msgId)
		root := ipc.ChunkEnd(b)
		b.FinishWithFileIdentifier(root, []byte("XCHN"))

		out.offset = currentSize
		outgoingChunksMutex.Unlock()

		payload = b.FinishedBytes()
		if len(payload) > len(respBuf) {
			return 0, 0 // Fatal: Chunk header overhead made it > 1MB?
		}
		copy(respBuf, payload)
		return int32(len(payload)), MSG_CHUNK
	}
	copy(respBuf, payload)
	return int32(len(payload)), shm.MsgType(msgId)

}
